import glob
import json
import os
import re
import shutil
import stat
import subprocess
import sys
import time
import traceback
import typing
from dataclasses import asdict, dataclass, fields, is_dataclass
from enum import Enum
from itertools import chain, repeat
from pathlib import Path
from subprocess import CalledProcessError
from typing import Dict, List, NamedTuple

from flytekit.extras.persistence import LatchPersistence
from latch_cli.extras.nextflow.file_persistence import download_files, stage_for_output, upload_files
from latch_cli.extras.nextflow.channel import get_mapper_inputs, get_boolean_value, get_mapper_outputs
from latch_cli.utils import check_exists_and_rename, get_parameter_json_value, urljoins

from latch.resources.tasks import custom_task
from latch.types.directory import LatchDir, LatchOutputDir
from latch.types.file import LatchFile

sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

task = custom_task(cpu=-1, memory=-1) # these limits are a lie and are ignored when generating the task spec



class Resparams_multiqc_methods_description_1086(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_multiqc_methods_description_1086(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_multiqc_methods_description_1086:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_methods_description"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_multiqc_methods_description_1086(
        res=out_channels.get("res", "")
    )


class Resconditional_params_multiqc_methods_description_1087(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_multiqc_methods_description_1087(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1086: typing.Union[str, None]
) -> Resconditional_params_multiqc_methods_description_1087:
    cond = ((channel_1086 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1086)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_multiqc_methods_description_1087(condition=res)


class Resthis_file__checkIfExists_true___params_multiqc_methods_descripti_1088(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def this_file__checkIfExists_true___params_multiqc_methods_descripti_1088(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1087: typing.Union[bool, None]
) -> Resthis_file__checkIfExists_true___params_multiqc_methods_descripti_1088:
    cond = ((condition_1087 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_methods_description"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resthis_file__checkIfExists_true___params_multiqc_methods_descripti_1088(
        res=out_channels.get("res", "")
    )


class Resthis_file__checkIfExists_true____projectDir_assets_methods_descr_1089(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def this_file__checkIfExists_true____projectDir_assets_methods_descr_1089(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1087: typing.Union[bool, None]
) -> Resthis_file__checkIfExists_true____projectDir_assets_methods_descr_1089:
    cond = ((condition_1087 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"GStringExpression":{"verbatimText":"$projectDir/assets/methods_description_template.yml","strings":[{"ConstantExpression":""},{"ConstantExpression":"/assets/methods_description_template.yml"}],"values":[{"VariableExpression":"projectDir"}]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resthis_file__checkIfExists_true____projectDir_assets_methods_descr_1089(
        res=out_channels.get("res", "")
    )


class Res_params_multiqc_methods_description____this_file__checkIfExists__1090(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_multiqc_methods_description____this_file__checkIfExists__1090(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1088: typing.Union[str, None],
    channel_1089: typing.Union[str, None]
) -> Res_params_multiqc_methods_description____this_file__checkIfExists__1090:
    cond = True

    if cond:
        res = channel_1088 or channel_1089
    else:
        print("TASK SKIPPED")
        res = None

    return Res_params_multiqc_methods_description____this_file__checkIfExists__1090(
        res=res
    )


class Resparams_arg_skip_deeparg_1102(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1102(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_arg_skip_deeparg_1102:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_deeparg"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1102(
        res=out_channels.get("res", "")
    )


class Res_params_run_arg_screening____params_arg_skip_deeparg__1103(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_run_arg_screening____params_arg_skip_deeparg__1103(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1102: typing.Union[str, None]
) -> Res_params_run_arg_screening____params_arg_skip_deeparg__1103:
    cond = ((channel_1102 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1102)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"run_arg_screening"}},{"ConstantExpression":"&&"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_run_arg_screening____params_arg_skip_deeparg__1103(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_hmmsearch_1104(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_hmmsearch_1104(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_amp_skip_hmmsearch_1104:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_hmmsearch"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_hmmsearch_1104(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_amplify_1105(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_amplify_1105(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_amp_skip_amplify_1105:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_amplify"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_amplify_1105(
        res=out_channels.get("res", "")
    )


class Res_params_amp_skip_hmmsearch____params_amp_skip_amplify__1106(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_amp_skip_hmmsearch____params_amp_skip_amplify__1106(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1104: typing.Union[str, None],
    channel_1105: typing.Union[str, None]
) -> Res_params_amp_skip_hmmsearch____params_amp_skip_amplify__1106:
    cond = ((channel_1104 is not None) and (channel_1105 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1104), json.loads(channel_1105)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_amp_skip_hmmsearch____params_amp_skip_amplify__1106(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_ampir_1107(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_ampir_1107(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_amp_skip_ampir_1107:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_ampir"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_ampir_1107(
        res=out_channels.get("res", "")
    )


class Res__params_amp_skip_hmmsearch____params_amp_skip_amplify_____param_1108(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_amp_skip_hmmsearch____params_amp_skip_amplify_____param_1108(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1106: typing.Union[str, None],
    channel_1107: typing.Union[str, None]
) -> Res__params_amp_skip_hmmsearch____params_amp_skip_amplify_____param_1108:
    cond = ((channel_1106 is not None) and (channel_1107 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1106), json.loads(channel_1107)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res__params_amp_skip_hmmsearch____params_amp_skip_amplify_____param_1108(
        res=out_channels.get("res", "")
    )


class Res_params_run_amp_screening______params_amp_skip_hmmsearch____para_1109(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_run_amp_screening______params_amp_skip_hmmsearch____para_1109(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1108: typing.Union[str, None]
) -> Res_params_run_amp_screening______params_amp_skip_hmmsearch____para_1109:
    cond = ((channel_1108 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1108)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"run_amp_screening"}},{"ConstantExpression":"&&"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_run_amp_screening______params_amp_skip_hmmsearch____para_1109(
        res=out_channels.get("res", "")
    )


class Res__params_run_arg_screening____params_arg_skip_deeparg______param_1110(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_run_arg_screening____params_arg_skip_deeparg______param_1110(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1103: typing.Union[str, None],
    channel_1109: typing.Union[str, None]
) -> Res__params_run_arg_screening____params_arg_skip_deeparg______param_1110:
    cond = ((channel_1103 is not None) and (channel_1109 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1103), json.loads(channel_1109)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res__params_run_arg_screening____params_arg_skip_deeparg______param_1110(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_hmmsearch_1111(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_hmmsearch_1111(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_bgc_skip_hmmsearch_1111:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_skip_hmmsearch"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_hmmsearch_1111(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_antismash_1112(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_antismash_1112(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_bgc_skip_antismash_1112:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_skip_antismash"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_antismash_1112(
        res=out_channels.get("res", "")
    )


class Res_params_bgc_skip_hmmsearch____params_bgc_skip_antismash__1113(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_bgc_skip_hmmsearch____params_bgc_skip_antismash__1113(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1111: typing.Union[str, None],
    channel_1112: typing.Union[str, None]
) -> Res_params_bgc_skip_hmmsearch____params_bgc_skip_antismash__1113:
    cond = ((channel_1111 is not None) and (channel_1112 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1111), json.loads(channel_1112)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_bgc_skip_hmmsearch____params_bgc_skip_antismash__1113(
        res=out_channels.get("res", "")
    )


class Res_params_run_bgc_screening_____params_bgc_skip_hmmsearch____param_1114(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_run_bgc_screening_____params_bgc_skip_hmmsearch____param_1114(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1113: typing.Union[str, None]
) -> Res_params_run_bgc_screening_____params_bgc_skip_hmmsearch____param_1114:
    cond = ((channel_1113 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1113)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"run_bgc_screening"}},{"ConstantExpression":"&&"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_run_bgc_screening_____params_bgc_skip_hmmsearch____param_1114(
        res=out_channels.get("res", "")
    )


class Res___params_run_arg_screening____params_arg_skip_deeparg______para_1115(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___params_run_arg_screening____params_arg_skip_deeparg______para_1115(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1110: typing.Union[str, None],
    channel_1114: typing.Union[str, None]
) -> Res___params_run_arg_screening____params_arg_skip_deeparg______para_1115:
    cond = ((channel_1110 is not None) and (channel_1114 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1110), json.loads(channel_1114)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res___params_run_arg_screening____params_arg_skip_deeparg______para_1115(
        res=out_channels.get("res", "")
    )


class Res___params_run_arg_screening____params_arg_skip_deeparg______para_1116(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___params_run_arg_screening____params_arg_skip_deeparg______para_1116(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1115: typing.Union[str, None]
) -> Res___params_run_arg_screening____params_arg_skip_deeparg______para_1116:
    cond = ((channel_1115 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1115)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res___params_run_arg_screening____params_arg_skip_deeparg______para_1116(
        res=out_channels.get("res", "")
    )


class Resconditional____params_run_arg_screening____params_arg_skip_deeparg______para_1117(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional____params_run_arg_screening____params_arg_skip_deeparg______para_1117(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1116: typing.Union[str, None]
) -> Resconditional____params_run_arg_screening____params_arg_skip_deeparg______para_1117:
    cond = ((channel_1116 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1116)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional____params_run_arg_screening____params_arg_skip_deeparg______para_1117(condition=res)


class Res_params_annotation_tool____prodigal__1118(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_annotation_tool____prodigal__1118(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None]
) -> Res_params_annotation_tool____prodigal__1118:
    cond = ((condition_1117 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"annotation_tool"}},"operation":"==","rightExpression":{"ConstantExpression":"prodigal"}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_annotation_tool____prodigal__1118(
        res=out_channels.get("res", "")
    )


class Res_params_annotation_tool____prodigal__1119(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_annotation_tool____prodigal__1119(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    channel_1118: typing.Union[str, None]
) -> Res_params_annotation_tool____prodigal__1119:
    cond = ((condition_1117 == True) and (channel_1118 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1118)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_annotation_tool____prodigal__1119(
        res=out_channels.get("res", "")
    )


class Resconditional__params_annotation_tool____prodigal__1120(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_annotation_tool____prodigal__1120(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    channel_1119: typing.Union[str, None]
) -> Resconditional__params_annotation_tool____prodigal__1120:
    cond = ((condition_1117 == True) and (channel_1119 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1119)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_annotation_tool____prodigal__1120(condition=res)


class ResChannel_fromSamplesheet_input__1093(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromSamplesheet_input__1093(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> ResChannel_fromSamplesheet_input__1093:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromSamplesheet","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"input"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromSamplesheet_input__1093(
        res=out_channels.get("res", "")
    )


class Resbranch_1094(NamedTuple):
    compressed: typing.Union[str, None]
    uncompressed: typing.Union[str, None]

@task(cache=True)
def branch_1094(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1093: typing.Union[str, None]
) -> Resbranch_1094:
    cond = ((channel_1093 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1093)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"branch","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}},"method":"toString","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}},"labels":["compressed"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}},"labels":["uncompressed"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"compressed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"compressed\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"uncompressed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"uncompressed\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'compressed': None, 'uncompressed': None}

    return Resbranch_1094(
        compressed=out_channels.get("compressed", ""),
        uncompressed=out_channels.get("uncompressed", "")
    )


@dataclass
class Dataclass_1095_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    compressed: str


class Res_1095_pre(NamedTuple):
    default: typing.List[Dataclass_1095_pre]

@task(cache=True)
def pre_adapter_GUNZIP_FASTA_PREP_1095_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    compressed: typing.Union[str, None]
) -> Res_1095_pre:
    cond = ((compressed is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1095_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'compressed': compressed})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1095_pre(default=result)

class Respost_adapter_GUNZIP_FASTA_PREP_1095_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1095_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_FASTA_PREP_1095_post(
    default: List[Dataclass_1095_post]
) -> Respost_adapter_GUNZIP_FASTA_PREP_1095_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_FASTA_PREP_1095_post, default)


@task(cache=True)
def GUNZIP_FASTA_PREP_1095(
    default: Dataclass_1095_pre
) -> Dataclass_1095_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.compressed)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gunzip/main.nf", "alias": "GUNZIP_FASTA_PREP", "name": "GUNZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_FASTA_PREP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_FASTA_PREP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_FASTA_PREP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1095_post(
        gunzip=out_channels.get(f"gunzip", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1097(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1097(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    gunzip: typing.Union[str, None],
    uncompressed: typing.Union[str, None]
) -> Resmix_1097:
    cond = ((gunzip is not None) and (uncompressed is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(gunzip), json.loads(uncompressed)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1097(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1098_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1097: str


class Res_1098_pre(NamedTuple):
    default: typing.List[Dataclass_1098_pre]

@task(cache=True)
def pre_adapter_BIOAWK_1098_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1097: typing.Union[str, None]
) -> Res_1098_pre:
    cond = ((channel_1097 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1098_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1097': channel_1097})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1098_pre(default=result)

class Respost_adapter_BIOAWK_1098_post(NamedTuple):
    output: typing.Union[str, None]
    longest: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1098_post:
    output: str
    longest: str
    versions: str

@task(cache=True)
def post_adapter_BIOAWK_1098_post(
    default: List[Dataclass_1098_post]
) -> Respost_adapter_BIOAWK_1098_post:
    return get_mapper_outputs(Respost_adapter_BIOAWK_1098_post, default)


@task(cache=True)
def BIOAWK_1098(
    default: Dataclass_1098_pre
) -> Dataclass_1098_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1097)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/bioawk/main.nf", "alias": "BIOAWK", "name": "BIOAWK"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BIOAWK","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"output\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BIOAWK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"longest\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BIOAWK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BIOAWK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1098_post(
        output=out_channels.get(f"output", ""),
        longest=out_channels.get(f"longest", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resjoin_1100(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_1100(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1097: typing.Union[str, None],
    longest: typing.Union[str, None]
) -> Resjoin_1100:
    cond = ((channel_1097 is not None) and (longest is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1097), json.loads(longest)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resjoin_1100(
        res=out_channels.get("res", "")
    )


class Resmap_1101(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1101(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1100: typing.Union[str, None]
) -> Resmap_1101:
    cond = ((channel_1100 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1100)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"meta"},"method":"clone","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"[","rightExpression":{"ConstantExpression":"longest_contig"}}},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"java.lang.Integer"}},"method":"parseInt","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"length"}]}}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"fasta"}]}}],"scope":{"declaredVariables":["meta_new"],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fasta","length"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1101(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1121_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1121_pre(NamedTuple):
    default: typing.List[Dataclass_1121_pre]

@task(cache=True)
def pre_adapter_PRODIGAL_GFF_1121_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1121_pre:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1121_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1121_pre(default=result)

class Respost_adapter_PRODIGAL_GFF_1121_post(NamedTuple):
    gene_annotations: typing.Union[str, None]
    nucleotide_fasta: typing.Union[str, None]
    amino_acid_fasta: typing.Union[str, None]
    all_gene_annotations: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1121_post:
    gene_annotations: str
    nucleotide_fasta: str
    amino_acid_fasta: str
    all_gene_annotations: str
    versions: str

@task(cache=True)
def post_adapter_PRODIGAL_GFF_1121_post(
    default: List[Dataclass_1121_post]
) -> Respost_adapter_PRODIGAL_GFF_1121_post:
    return get_mapper_outputs(Respost_adapter_PRODIGAL_GFF_1121_post, default)


@task(cache=True)
def PRODIGAL_GFF_1121(
    default: Dataclass_1121_pre
) -> Dataclass_1121_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/prodigal/main.nf", "alias": "PRODIGAL_GFF", "name": "PRODIGAL"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PRODIGAL_GFF","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"gff"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gene_annotations\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"nucleotide_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"amino_acid_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_gene_annotations\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1121_post(
        gene_annotations=out_channels.get(f"gene_annotations", ""),
        nucleotide_fasta=out_channels.get(f"nucleotide_fasta", ""),
        amino_acid_fasta=out_channels.get(f"amino_acid_fasta", ""),
        all_gene_annotations=out_channels.get(f"all_gene_annotations", ""),
        versions=out_channels.get(f"versions", "")
    )


@dataclass
class Dataclass_1123_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    nucleotide_fasta: str


class Res_1123_pre(NamedTuple):
    default: typing.List[Dataclass_1123_pre]

@task(cache=True)
def pre_adapter_GUNZIP_PRODIGAL_FNA_1123_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    nucleotide_fasta: typing.Union[str, None]
) -> Res_1123_pre:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (nucleotide_fasta is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1123_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'nucleotide_fasta': nucleotide_fasta})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1123_pre(default=result)

class Respost_adapter_GUNZIP_PRODIGAL_FNA_1123_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1123_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_PRODIGAL_FNA_1123_post(
    default: List[Dataclass_1123_post]
) -> Respost_adapter_GUNZIP_PRODIGAL_FNA_1123_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_PRODIGAL_FNA_1123_post, default)


@task(cache=True)
def GUNZIP_PRODIGAL_FNA_1123(
    default: Dataclass_1123_pre
) -> Dataclass_1123_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.nucleotide_fasta)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gunzip/main.nf", "alias": "GUNZIP_PRODIGAL_FNA", "name": "GUNZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_PRODIGAL_FNA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_PRODIGAL_FNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_PRODIGAL_FNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1123_post(
        gunzip=out_channels.get(f"gunzip", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResChannel_empty___1136(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1136(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None]
) -> ResChannel_empty___1136:
    cond = ((condition_1117 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1136(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_annotation_fna_1141(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_annotation_fna_1141(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    gunzip: typing.Union[str, None],
    channel_1136: typing.Union[str, None]
) -> ResMerge_ch_annotation_fna_1141:
    cond = True

    if cond:
        res = gunzip or channel_1136
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_annotation_fna_1141(
        res=res
    )


class Resparams_run_amp_screening_1144(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_run_amp_screening_1144(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_run_amp_screening_1144:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"run_amp_screening"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_run_amp_screening_1144(
        res=out_channels.get("res", "")
    )


class Resconditional_params_run_amp_screening_1145(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_run_amp_screening_1145(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1144: typing.Union[str, None]
) -> Resconditional_params_run_amp_screening_1145:
    cond = ((channel_1144 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1144)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_run_amp_screening_1145(condition=res)


class Resparams_amp_skip_macrel_1159(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_macrel_1159(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> Resparams_amp_skip_macrel_1159:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_macrel"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_macrel_1159(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_macrel_1160(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_macrel_1160(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1159: typing.Union[str, None]
) -> Resparams_amp_skip_macrel_1160:
    cond = ((condition_1145 == True) and (channel_1159 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1159)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_macrel_1160(
        res=out_channels.get("res", "")
    )


class Resconditional_params_amp_skip_macrel_1161(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_amp_skip_macrel_1161(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1160: typing.Union[str, None]
) -> Resconditional_params_amp_skip_macrel_1161:
    cond = ((condition_1145 == True) and (channel_1160 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1160)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_amp_skip_macrel_1161(condition=res)


class ResChannel_empty___1150(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1150(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> ResChannel_empty___1150:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1150(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1162_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1162_pre(NamedTuple):
    default: typing.List[Dataclass_1162_pre]

@task(cache=True)
def pre_adapter_MACREL_CONTIGS_1162_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1162_pre:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1162_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1162_pre(default=result)

class Respost_adapter_MACREL_CONTIGS_1162_post(NamedTuple):
    smorfs: typing.Union[str, None]
    all_orfs: typing.Union[str, None]
    amp_prediction: typing.Union[str, None]
    readme_file: typing.Union[str, None]
    log_file: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1162_post:
    smorfs: str
    all_orfs: str
    amp_prediction: str
    readme_file: str
    log_file: str
    versions: str

@task(cache=True)
def post_adapter_MACREL_CONTIGS_1162_post(
    default: List[Dataclass_1162_post]
) -> Respost_adapter_MACREL_CONTIGS_1162_post:
    return get_mapper_outputs(Respost_adapter_MACREL_CONTIGS_1162_post, default)


@task(cache=True)
def MACREL_CONTIGS_1162(
    default: Dataclass_1162_pre
) -> Dataclass_1162_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/macrel/contigs/main.nf", "alias": "MACREL_CONTIGS", "name": "MACREL_CONTIGS"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MACREL_CONTIGS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"smorfs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MACREL_CONTIGS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_orfs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MACREL_CONTIGS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"amp_prediction\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MACREL_CONTIGS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"readme_file\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MACREL_CONTIGS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_file\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MACREL_CONTIGS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MACREL_CONTIGS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1162_post(
        smorfs=out_channels.get(f"smorfs", ""),
        all_orfs=out_channels.get(f"all_orfs", ""),
        amp_prediction=out_channels.get(f"amp_prediction", ""),
        readme_file=out_channels.get(f"readme_file", ""),
        log_file=out_channels.get(f"log_file", ""),
        versions=out_channels.get(f"versions", "")
    )


@dataclass
class Dataclass_1165_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    all_orfs: str


class Res_1165_pre(NamedTuple):
    default: typing.List[Dataclass_1165_pre]

@task(cache=True)
def pre_adapter_GUNZIP_MACREL_ORFS_1165_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    all_orfs: typing.Union[str, None]
) -> Res_1165_pre:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (all_orfs is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1165_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'all_orfs': all_orfs})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1165_pre(default=result)

class Respost_adapter_GUNZIP_MACREL_ORFS_1165_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1165_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_MACREL_ORFS_1165_post(
    default: List[Dataclass_1165_post]
) -> Respost_adapter_GUNZIP_MACREL_ORFS_1165_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_MACREL_ORFS_1165_post, default)


@task(cache=True)
def GUNZIP_MACREL_ORFS_1165(
    default: Dataclass_1165_pre
) -> Dataclass_1165_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.all_orfs)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gunzip/main.nf", "alias": "GUNZIP_MACREL_ORFS", "name": "GUNZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_MACREL_ORFS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_MACREL_ORFS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_MACREL_ORFS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1165_post(
        gunzip=out_channels.get(f"gunzip", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1169(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1169(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1150: typing.Union[str, None],
    gunzip: typing.Union[str, None]
) -> Resmix_1169:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1150 is not None) and (gunzip is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1150), json.loads(gunzip)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1169(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_macrel_faa_1171(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_macrel_faa_1171(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1169: typing.Union[str, None],
    channel_1150: typing.Union[str, None]
) -> ResMerge_ch_macrel_faa_1171:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1169 or channel_1150
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_macrel_faa_1171(
        res=res
    )


class Resparams_amp_skip_hmmsearch_1183(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_hmmsearch_1183(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> Resparams_amp_skip_hmmsearch_1183:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_hmmsearch"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_hmmsearch_1183(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_hmmsearch_1184(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_hmmsearch_1184(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1183: typing.Union[str, None]
) -> Resparams_amp_skip_hmmsearch_1184:
    cond = ((condition_1145 == True) and (channel_1183 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1183)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_hmmsearch_1184(
        res=out_channels.get("res", "")
    )


class Resconditional_params_amp_skip_hmmsearch_1185(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_amp_skip_hmmsearch_1185(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1184: typing.Union[str, None]
) -> Resconditional_params_amp_skip_hmmsearch_1185:
    cond = ((condition_1145 == True) and (channel_1184 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1184)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_amp_skip_hmmsearch_1185(condition=res)


class Resparams_amp_hmmsearch_models_1186(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_hmmsearch_models_1186(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None]
) -> Resparams_amp_hmmsearch_models_1186:
    cond = ((condition_1145 == True) and (condition_1185 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_hmmsearch_models"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_hmmsearch_models_1186(
        res=out_channels.get("res", "")
    )


class Resconditional_params_amp_hmmsearch_models_1187(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_amp_hmmsearch_models_1187(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    channel_1186: typing.Union[str, None]
) -> Resconditional_params_amp_hmmsearch_models_1187:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (channel_1186 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1186)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_amp_hmmsearch_models_1187(condition=res)


class Resthis_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1189(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def this_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1189(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    condition_1187: typing.Union[bool, None]
) -> Resthis_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1189:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (condition_1187 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"error","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"[nf-core/funcscan] error: hmm model files not found for --amp_hmmsearch_models! Please check input."}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resthis_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1189(
        res=out_channels.get("res", "")
    )


class ResChannel_of__id_ampcombi_complete_summary___1207(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_of__id_ampcombi_complete_summary___1207(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> ResChannel_of__id_ampcombi_complete_summary___1207:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"of","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"id"},"valueExpression":{"ConstantExpression":"ampcombi_complete_summary"}}}]}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_of__id_ampcombi_complete_summary___1207(
        res=out_channels.get("res", "")
    )


class ResChannel_empty___1149(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1149(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> ResChannel_empty___1149:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1149(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_ampir_1175(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_ampir_1175(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> Resparams_amp_skip_ampir_1175:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_ampir"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_ampir_1175(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_ampir_1176(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_ampir_1176(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1175: typing.Union[str, None]
) -> Resparams_amp_skip_ampir_1176:
    cond = ((condition_1145 == True) and (channel_1175 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1175)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_ampir_1176(
        res=out_channels.get("res", "")
    )


class Resconditional_params_amp_skip_ampir_1177(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_amp_skip_ampir_1177(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1176: typing.Union[str, None]
) -> Resconditional_params_amp_skip_ampir_1177:
    cond = ((condition_1145 == True) and (channel_1176 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1176)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_amp_skip_ampir_1177(condition=res)


class Resparams_amp_skip_amplify_1151(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_amplify_1151(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> Resparams_amp_skip_amplify_1151:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_skip_amplify"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_amplify_1151(
        res=out_channels.get("res", "")
    )


class Resparams_amp_skip_amplify_1152(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_skip_amplify_1152(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1151: typing.Union[str, None]
) -> Resparams_amp_skip_amplify_1152:
    cond = ((condition_1145 == True) and (channel_1151 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1151)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_skip_amplify_1152(
        res=out_channels.get("res", "")
    )


class Resconditional_params_amp_skip_amplify_1153(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_amp_skip_amplify_1153(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1152: typing.Union[str, None]
) -> Resconditional_params_amp_skip_amplify_1153:
    cond = ((condition_1145 == True) and (channel_1152 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1152)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_amp_skip_amplify_1153(condition=res)


class ResChannel_empty___1148(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1148(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> ResChannel_empty___1148:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1148(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1122_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    amino_acid_fasta: str


class Res_1122_pre(NamedTuple):
    default: typing.List[Dataclass_1122_pre]

@task(cache=True)
def pre_adapter_GUNZIP_PRODIGAL_FAA_1122_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    amino_acid_fasta: typing.Union[str, None]
) -> Res_1122_pre:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (amino_acid_fasta is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1122_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'amino_acid_fasta': amino_acid_fasta})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1122_pre(default=result)

class Respost_adapter_GUNZIP_PRODIGAL_FAA_1122_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1122_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_PRODIGAL_FAA_1122_post(
    default: List[Dataclass_1122_post]
) -> Respost_adapter_GUNZIP_PRODIGAL_FAA_1122_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_PRODIGAL_FAA_1122_post, default)


@task(cache=True)
def GUNZIP_PRODIGAL_FAA_1122(
    default: Dataclass_1122_pre
) -> Dataclass_1122_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.amino_acid_fasta)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gunzip/main.nf", "alias": "GUNZIP_PRODIGAL_FAA", "name": "GUNZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_PRODIGAL_FAA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_PRODIGAL_FAA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_PRODIGAL_FAA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1122_post(
        gunzip=out_channels.get(f"gunzip", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResChannel_empty___1135(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1135(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None]
) -> ResChannel_empty___1135:
    cond = ((condition_1117 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1135(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_annotation_faa_1139(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_annotation_faa_1139(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    gunzip: typing.Union[str, None],
    channel_1135: typing.Union[str, None]
) -> ResMerge_ch_annotation_faa_1139:
    cond = True

    if cond:
        res = gunzip or channel_1135
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_annotation_faa_1139(
        res=res
    )


class Resfilter_1146(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_1146(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1139: typing.Union[str, None]
) -> Resfilter_1146:
    cond = ((condition_1145 == True) and (channel_1139 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1139)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}},"ifBlock":{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}},"method":"warn","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"Annotation of following sample produced produced an empty FAA file. AMP screening tools requiring this file will not be executed: $meta.id","strings":[{"ConstantExpression":"Annotation of following sample produced produced an empty FAA file. AMP screening tools requiring this file will not be executed: "},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}]}}]}}}},"labels":[]}},"elseBlock":{"EmptyStatement":null},"labels":[]}},{"ReturnStatement":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":["meta","file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfilter_1146(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1154_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1146: str


class Res_1154_pre(NamedTuple):
    default: typing.List[Dataclass_1154_pre]

@task(cache=True)
def pre_adapter_AMPLIFY_PREDICT_1154_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1153: typing.Union[bool, None],
    channel_1146: typing.Union[str, None]
) -> Res_1154_pre:
    cond = ((condition_1145 == True) and (condition_1153 == True) and (channel_1146 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1154_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1146': channel_1146})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1154_pre(default=result)

class Respost_adapter_AMPLIFY_PREDICT_1154_post(NamedTuple):
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1154_post:
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_AMPLIFY_PREDICT_1154_post(
    default: List[Dataclass_1154_post]
) -> Respost_adapter_AMPLIFY_PREDICT_1154_post:
    return get_mapper_outputs(Respost_adapter_AMPLIFY_PREDICT_1154_post, default)


@task(cache=True)
def AMPLIFY_PREDICT_1154(
    default: Dataclass_1154_pre
) -> Dataclass_1154_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1146)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/amplify/predict/main.nf", "alias": "AMPLIFY_PREDICT", "name": "AMPLIFY_PREDICT"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"AMPLIFY_PREDICT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPLIFY_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPLIFY_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1154_post(
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1156(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1156(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1153: typing.Union[bool, None],
    channel_1148: typing.Union[str, None],
    tsv: typing.Union[str, None]
) -> Resmix_1156:
    cond = ((condition_1145 == True) and (condition_1153 == True) and (channel_1148 is not None) and (tsv is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1148), json.loads(tsv)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1156(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_ampresults_for_ampcombi_1157(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_ampresults_for_ampcombi_1157(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1156: typing.Union[str, None],
    channel_1148: typing.Union[str, None]
) -> ResMerge_ch_ampresults_for_ampcombi_1157:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1156 or channel_1148
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_ampresults_for_ampcombi_1157(
        res=res
    )


@dataclass
class Dataclass_1164_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    amp_prediction: str


class Res_1164_pre(NamedTuple):
    default: typing.List[Dataclass_1164_pre]

@task(cache=True)
def pre_adapter_GUNZIP_MACREL_PRED_1164_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    amp_prediction: typing.Union[str, None]
) -> Res_1164_pre:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (amp_prediction is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1164_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'amp_prediction': amp_prediction})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1164_pre(default=result)

class Respost_adapter_GUNZIP_MACREL_PRED_1164_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1164_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_MACREL_PRED_1164_post(
    default: List[Dataclass_1164_post]
) -> Respost_adapter_GUNZIP_MACREL_PRED_1164_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_MACREL_PRED_1164_post, default)


@task(cache=True)
def GUNZIP_MACREL_PRED_1164(
    default: Dataclass_1164_pre
) -> Dataclass_1164_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.amp_prediction)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gunzip/main.nf", "alias": "GUNZIP_MACREL_PRED", "name": "GUNZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_MACREL_PRED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_MACREL_PRED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_MACREL_PRED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1164_post(
        gunzip=out_channels.get(f"gunzip", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1168(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1168(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1157: typing.Union[str, None],
    gunzip: typing.Union[str, None]
) -> Resmix_1168:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1157 is not None) and (gunzip is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1157), json.loads(gunzip)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1168(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_ampresults_for_ampcombi_1172(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_ampresults_for_ampcombi_1172(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1168: typing.Union[str, None],
    channel_1157: typing.Union[str, None]
) -> ResMerge_ch_ampresults_for_ampcombi_1172:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1168 or channel_1157
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_ampresults_for_ampcombi_1172(
        res=res
    )


@dataclass
class Dataclass_1178_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1146: str


class Res_1178_pre(NamedTuple):
    default: typing.List[Dataclass_1178_pre]

@task(cache=True)
def pre_adapter_AMPIR_1178_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1177: typing.Union[bool, None],
    channel_1146: typing.Union[str, None]
) -> Res_1178_pre:
    cond = ((condition_1145 == True) and (condition_1177 == True) and (channel_1146 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1178_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1146': channel_1146})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1178_pre(default=result)

class Respost_adapter_AMPIR_1178_post(NamedTuple):
    amps_faa: typing.Union[str, None]
    amps_tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1178_post:
    amps_faa: str
    amps_tsv: str
    versions: str

@task(cache=True)
def post_adapter_AMPIR_1178_post(
    default: List[Dataclass_1178_post]
) -> Respost_adapter_AMPIR_1178_post:
    return get_mapper_outputs(Respost_adapter_AMPIR_1178_post, default)


@task(cache=True)
def AMPIR_1178(
    default: Dataclass_1178_pre
) -> Dataclass_1178_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1146)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/ampir/main.nf", "alias": "AMPIR", "name": "AMPIR"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"AMPIR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_ampir_model"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_ampir_minlength"}},{"ConstantExpression":0.0}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"amps_faa\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPIR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"amps_tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPIR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPIR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1178_post(
        amps_faa=out_channels.get(f"amps_faa", ""),
        amps_tsv=out_channels.get(f"amps_tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1180(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1180(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1177: typing.Union[bool, None],
    channel_1172: typing.Union[str, None],
    amps_tsv: typing.Union[str, None]
) -> Resmix_1180:
    cond = ((condition_1145 == True) and (condition_1177 == True) and (channel_1172 is not None) and (amps_tsv is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1172), json.loads(amps_tsv)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1180(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_ampresults_for_ampcombi_1181(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_ampresults_for_ampcombi_1181(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1180: typing.Union[str, None],
    channel_1172: typing.Union[str, None]
) -> ResMerge_ch_ampresults_for_ampcombi_1181:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1180 or channel_1172
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_ampresults_for_ampcombi_1181(
        res=res
    )


class ResgroupTuple_1196(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_1196(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1181: typing.Union[str, None]
) -> ResgroupTuple_1196:
    cond = ((condition_1145 == True) and (channel_1181 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1181)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResgroupTuple_1196(
        res=out_channels.get("res", "")
    )


class Resmix_1170(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1170(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1146: typing.Union[str, None],
    channel_1169: typing.Union[str, None]
) -> Resmix_1170:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1146 is not None) and (channel_1169 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1146), json.loads(channel_1169)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1170(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_faa_for_ampcombi_1173(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_faa_for_ampcombi_1173(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1170: typing.Union[str, None],
    channel_1146: typing.Union[str, None]
) -> ResMerge_ch_faa_for_ampcombi_1173:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1170 or channel_1146
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_faa_for_ampcombi_1173(
        res=res
    )


class Resjoin_1197(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_1197(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1196: typing.Union[str, None],
    channel_1173: typing.Union[str, None]
) -> Resjoin_1197:
    cond = ((condition_1145 == True) and (channel_1196 is not None) and (channel_1173 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1196), json.loads(channel_1173)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resjoin_1197(
        res=out_channels.get("res", "")
    )


class ResmultiMap_1198(NamedTuple):
    input: typing.Union[str, None]
    faa: typing.Union[str, None]

@task(cache=True)
def multiMap_1198(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1197: typing.Union[str, None]
) -> ResmultiMap_1198:
    cond = ((condition_1145 == True) and (channel_1197 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1197)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"multiMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}]},"labels":["input"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":2}}},"labels":["faa"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"input\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"input\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"faa\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"faa\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'input': None, 'faa': None}

    return ResmultiMap_1198(
        input=out_channels.get("input", ""),
        faa=out_channels.get("faa", "")
    )


class Resparams_amp_ampcombi_db_1199(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_amp_ampcombi_db_1199(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> Resparams_amp_ampcombi_db_1199:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_ampcombi_db"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_amp_ampcombi_db_1199(
        res=out_channels.get("res", "")
    )


class Resconditional_params_amp_ampcombi_db_1200(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_amp_ampcombi_db_1200(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1199: typing.Union[str, None]
) -> Resconditional_params_amp_ampcombi_db_1200:
    cond = ((condition_1145 == True) and (channel_1199 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1199)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_amp_ampcombi_db_1200(condition=res)


class ResChannel_fromPath__checkIfExists_true___params_amp_ampcombi_db__1201(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_amp_ampcombi_db__1201(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1200: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_amp_ampcombi_db__1201:
    cond = ((condition_1145 == True) and (condition_1200 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_ampcombi_db"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_amp_ampcombi_db__1201(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1202_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir


class Res_1202_pre(NamedTuple):
    default: typing.List[Dataclass_1202_pre]

@task(cache=True)
def pre_adapter_DRAMP_DOWNLOAD_1202_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1200: typing.Union[bool, None]
) -> Res_1202_pre:
    cond = ((condition_1145 == True) and (condition_1200 == False))

    if cond:
        result = get_mapper_inputs(Dataclass_1202_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1202_pre(default=result)

class Respost_adapter_DRAMP_DOWNLOAD_1202_post(NamedTuple):
    db: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1202_post:
    db: str
    versions: str

@task(cache=True)
def post_adapter_DRAMP_DOWNLOAD_1202_post(
    default: List[Dataclass_1202_post]
) -> Respost_adapter_DRAMP_DOWNLOAD_1202_post:
    return get_mapper_outputs(Respost_adapter_DRAMP_DOWNLOAD_1202_post, default)


@task(cache=True)
def DRAMP_DOWNLOAD_1202(
    default: Dataclass_1202_pre
) -> Dataclass_1202_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = []

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/local/dramp_download.nf", "alias": "DRAMP_DOWNLOAD", "name": "DRAMP_DOWNLOAD"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DRAMP_DOWNLOAD","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"db\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DRAMP_DOWNLOAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DRAMP_DOWNLOAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1202_post(
        db=out_channels.get(f"db", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResMerge_ch_ampcombi_input_db_1203(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_ampcombi_input_db_1203(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1201: typing.Union[str, None],
    db: typing.Union[str, None]
) -> ResMerge_ch_ampcombi_input_db_1203:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1201 or db
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_ampcombi_input_db_1203(
        res=res
    )


@dataclass
class Dataclass_1204_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    input: str
    faa: str
    channel_1203: str


class Res_1204_pre(NamedTuple):
    default: typing.List[Dataclass_1204_pre]

@task(cache=True)
def pre_adapter_AMPCOMBI_1204_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    input: typing.Union[str, None],
    faa: typing.Union[str, None],
    channel_1203: typing.Union[str, None]
) -> Res_1204_pre:
    cond = ((condition_1145 == True) and (input is not None) and (faa is not None) and (channel_1203 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1204_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'input': input, 'faa': faa, 'channel_1203': channel_1203})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1204_pre(default=result)

class Respost_adapter_AMPCOMBI_1204_post(NamedTuple):
    sample_dir: typing.Union[str, None]
    txt: typing.Union[str, None]
    csv: typing.Union[str, None]
    faa: typing.Union[str, None]
    summary_csv: typing.Union[str, None]
    summary_html: typing.Union[str, None]
    log: typing.Union[str, None]
    results_db: typing.Union[str, None]
    results_db_dmnd: typing.Union[str, None]
    results_db_fasta: typing.Union[str, None]
    results_db_tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1204_post:
    sample_dir: str
    txt: str
    csv: str
    faa: str
    summary_csv: str
    summary_html: str
    log: str
    results_db: str
    results_db_dmnd: str
    results_db_fasta: str
    results_db_tsv: str
    versions: str

@task(cache=True)
def post_adapter_AMPCOMBI_1204_post(
    default: List[Dataclass_1204_post]
) -> Respost_adapter_AMPCOMBI_1204_post:
    return get_mapper_outputs(Respost_adapter_AMPCOMBI_1204_post, default)


@task(cache=True)
def AMPCOMBI_1204(
    default: Dataclass_1204_pre
) -> Dataclass_1204_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.input),json.loads(default.faa),json.loads(default.channel_1203)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/ampcombi/main.nf", "alias": "AMPCOMBI", "name": "AMPCOMBI"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"AMPCOMBI","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sample_dir\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"faa\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary_csv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary_html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results_db\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results_db_dmnd\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results_db_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results_db_tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMPCOMBI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1204_post(
        sample_dir=out_channels.get(f"sample_dir", ""),
        txt=out_channels.get(f"txt", ""),
        csv=out_channels.get(f"csv", ""),
        faa=out_channels.get(f"faa", ""),
        summary_csv=out_channels.get(f"summary_csv", ""),
        summary_html=out_channels.get(f"summary_html", ""),
        log=out_channels.get(f"log", ""),
        results_db=out_channels.get(f"results_db", ""),
        results_db_dmnd=out_channels.get(f"results_db_dmnd", ""),
        results_db_fasta=out_channels.get(f"results_db_fasta", ""),
        results_db_tsv=out_channels.get(f"results_db_tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1205(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1205(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1149: typing.Union[str, None],
    csv: typing.Union[str, None]
) -> Resmix_1205:
    cond = ((condition_1145 == True) and (channel_1149 is not None) and (csv is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1149), json.loads(csv)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1205(
        res=out_channels.get("res", "")
    )


class ResmultiMap_1206(NamedTuple):
    input: typing.Union[str, None]
    summary: typing.Union[str, None]

@task(cache=True)
def multiMap_1206(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1205: typing.Union[str, None]
) -> ResmultiMap_1206:
    cond = ((condition_1145 == True) and (channel_1205 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1205)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"multiMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}}]},"labels":["input"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}},"labels":["summary"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"input\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"input\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"summary\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'input': None, 'summary': None}

    return ResmultiMap_1206(
        input=out_channels.get("input", ""),
        summary=out_channels.get("summary", "")
    )


class RescollectFile_1208(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_1208(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    summary: typing.Union[str, None]
) -> RescollectFile_1208:
    cond = ((condition_1145 == True) and (summary is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(summary)]

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"ampcombi_complete_summary.csv"}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"keepHeader"},"valueExpression":{"ConstantExpression":true}}}]}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RescollectFile_1208(
        res=out_channels.get("res", "")
    )


class Rescombine_1209(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_1209(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1207: typing.Union[str, None],
    channel_1208: typing.Union[str, None]
) -> Rescombine_1209:
    cond = ((condition_1145 == True) and (channel_1207 is not None) and (channel_1208 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1207), json.loads(channel_1208)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescombine_1209(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1210_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1209: str


class Res_1210_pre(NamedTuple):
    default: typing.List[Dataclass_1210_pre]

@task(cache=True)
def pre_adapter_TABIX_BGZIP_1210_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1209: typing.Union[str, None]
) -> Res_1210_pre:
    cond = ((condition_1145 == True) and (channel_1209 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1210_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1209': channel_1209})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1210_pre(default=result)

class Respost_adapter_TABIX_BGZIP_1210_post(NamedTuple):
    output: typing.Union[str, None]
    gzi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1210_post:
    output: str
    gzi: str
    versions: str

@task(cache=True)
def post_adapter_TABIX_BGZIP_1210_post(
    default: List[Dataclass_1210_post]
) -> Respost_adapter_TABIX_BGZIP_1210_post:
    return get_mapper_outputs(Respost_adapter_TABIX_BGZIP_1210_post, default)


@task(cache=True)
def TABIX_BGZIP_1210(
    default: Dataclass_1210_pre
) -> Dataclass_1210_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1209)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/tabix/bgzip/main.nf", "alias": "TABIX_BGZIP", "name": "TABIX_BGZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TABIX_BGZIP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"output\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TABIX_BGZIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gzi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TABIX_BGZIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TABIX_BGZIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1210_post(
        output=out_channels.get(f"output", ""),
        gzi=out_channels.get(f"gzi", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resparams_run_bgc_screening_1372(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_run_bgc_screening_1372(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_run_bgc_screening_1372:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"run_bgc_screening"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_run_bgc_screening_1372(
        res=out_channels.get("res", "")
    )


class Resconditional_params_run_bgc_screening_1373(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_run_bgc_screening_1373(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1372: typing.Union[str, None]
) -> Resconditional_params_run_bgc_screening_1373:
    cond = ((channel_1372 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1372)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_run_bgc_screening_1373(condition=res)


class Res_params_save_annotations____true__1127(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_save_annotations____true__1127(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None]
) -> Res_params_save_annotations____true__1127:
    cond = ((condition_1117 == True) and (condition_1120 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"save_annotations"}},"operation":"==","rightExpression":{"ConstantExpression":true}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_save_annotations____true__1127(
        res=out_channels.get("res", "")
    )


class Res_params_save_annotations____true__1128(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_save_annotations____true__1128(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    channel_1127: typing.Union[str, None]
) -> Res_params_save_annotations____true__1128:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (channel_1127 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1127)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_save_annotations____true__1128(
        res=out_channels.get("res", "")
    )


class Resconditional__params_save_annotations____true__1129(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_save_annotations____true__1129(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    channel_1128: typing.Union[str, None]
) -> Resconditional__params_save_annotations____true__1129:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (channel_1128 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1128)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_save_annotations____true__1129(condition=res)


@dataclass
class Dataclass_1130_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1130_pre(NamedTuple):
    default: typing.List[Dataclass_1130_pre]

@task(cache=True)
def pre_adapter_PRODIGAL_GBK_1130_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    condition_1129: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1130_pre:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (condition_1129 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1130_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1130_pre(default=result)

class Respost_adapter_PRODIGAL_GBK_1130_post(NamedTuple):
    gene_annotations: typing.Union[str, None]
    nucleotide_fasta: typing.Union[str, None]
    amino_acid_fasta: typing.Union[str, None]
    all_gene_annotations: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1130_post:
    gene_annotations: str
    nucleotide_fasta: str
    amino_acid_fasta: str
    all_gene_annotations: str
    versions: str

@task(cache=True)
def post_adapter_PRODIGAL_GBK_1130_post(
    default: List[Dataclass_1130_post]
) -> Respost_adapter_PRODIGAL_GBK_1130_post:
    return get_mapper_outputs(Respost_adapter_PRODIGAL_GBK_1130_post, default)


@task(cache=True)
def PRODIGAL_GBK_1130(
    default: Dataclass_1130_pre
) -> Dataclass_1130_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/prodigal/main.nf", "alias": "PRODIGAL_GBK", "name": "PRODIGAL"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PRODIGAL_GBK","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"gbk"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gene_annotations\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GBK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"nucleotide_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GBK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"amino_acid_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GBK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_gene_annotations\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GBK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRODIGAL_GBK\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1130_post(
        gene_annotations=out_channels.get(f"gene_annotations", ""),
        nucleotide_fasta=out_channels.get(f"nucleotide_fasta", ""),
        amino_acid_fasta=out_channels.get(f"amino_acid_fasta", ""),
        all_gene_annotations=out_channels.get(f"all_gene_annotations", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResChannel_empty___1126(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1126(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None]
) -> ResChannel_empty___1126:
    cond = ((condition_1117 == True) and (condition_1120 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1126(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_annotation_gbk_1132(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_annotation_gbk_1132(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    gene_annotations: typing.Union[str, None],
    channel_1126: typing.Union[str, None]
) -> ResMerge_ch_annotation_gbk_1132:
    cond = ((condition_1117 == True) and (condition_1120 == True))

    if cond:
        res = gene_annotations or channel_1126
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_annotation_gbk_1132(
        res=res
    )


class ResChannel_empty___1138(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1138(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None]
) -> ResChannel_empty___1138:
    cond = ((condition_1117 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1138(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_annotation_gbk_1142(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_annotation_gbk_1142(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1132: typing.Union[str, None],
    channel_1138: typing.Union[str, None]
) -> ResMerge_ch_annotation_gbk_1142:
    cond = True

    if cond:
        res = channel_1132 or channel_1138
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_annotation_gbk_1142(
        res=res
    )


class Resfilter_1376(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_1376(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1142: typing.Union[str, None]
) -> Resfilter_1376:
    cond = ((condition_1373 == True) and (channel_1142 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1142)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}},"ifBlock":{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}},"method":"warn","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"Annotation of following sample produced produced an empty GBK file. AMP screening tools requiring this file will not be executed: $meta.id","strings":[{"ConstantExpression":"Annotation of following sample produced produced an empty GBK file. AMP screening tools requiring this file will not be executed: "},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}]}}]}}}},"labels":[]}},"elseBlock":{"EmptyStatement":null},"labels":[]}},{"ReturnStatement":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":["meta","file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfilter_1376(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_hmmsearch_1454(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_hmmsearch_1454(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None]
) -> Resparams_bgc_skip_hmmsearch_1454:
    cond = ((condition_1373 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_skip_hmmsearch"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_hmmsearch_1454(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_hmmsearch_1455(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_hmmsearch_1455(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1454: typing.Union[str, None]
) -> Resparams_bgc_skip_hmmsearch_1455:
    cond = ((condition_1373 == True) and (channel_1454 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1454)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_hmmsearch_1455(
        res=out_channels.get("res", "")
    )


class Resconditional_params_bgc_skip_hmmsearch_1456(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bgc_skip_hmmsearch_1456(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1455: typing.Union[str, None]
) -> Resconditional_params_bgc_skip_hmmsearch_1456:
    cond = ((condition_1373 == True) and (channel_1455 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1455)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bgc_skip_hmmsearch_1456(condition=res)


class Resparams_bgc_hmmsearch_models_1457(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_hmmsearch_models_1457(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None]
) -> Resparams_bgc_hmmsearch_models_1457:
    cond = ((condition_1373 == True) and (condition_1456 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_hmmsearch_models"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_hmmsearch_models_1457(
        res=out_channels.get("res", "")
    )


class Resconditional_params_bgc_hmmsearch_models_1458(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bgc_hmmsearch_models_1458(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    channel_1457: typing.Union[str, None]
) -> Resconditional_params_bgc_hmmsearch_models_1458:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (channel_1457 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1457)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bgc_hmmsearch_models_1458(condition=res)


class Resthis_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1460(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def this_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1460(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    condition_1458: typing.Union[bool, None]
) -> Resthis_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1460:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (condition_1458 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"error","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"[nf-core/funcscan] error: hmm model files not found for --bgc_hmmsearch_models! Please check input."}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resthis_error__nf_core_funcscan__error__hmm_model_files_not_found_f_1460(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_gecco_1441(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_gecco_1441(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None]
) -> Resparams_bgc_skip_gecco_1441:
    cond = ((condition_1373 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_skip_gecco"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_gecco_1441(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_gecco_1442(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_gecco_1442(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1441: typing.Union[str, None]
) -> Resparams_bgc_skip_gecco_1442:
    cond = ((condition_1373 == True) and (channel_1441 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1441)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_gecco_1442(
        res=out_channels.get("res", "")
    )


class Resconditional_params_bgc_skip_gecco_1443(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bgc_skip_gecco_1443(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1442: typing.Union[str, None]
) -> Resconditional_params_bgc_skip_gecco_1443:
    cond = ((condition_1373 == True) and (channel_1442 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1442)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bgc_skip_gecco_1443(condition=res)


class Resparams_bgc_skip_deepbgc_1425(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_deepbgc_1425(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None]
) -> Resparams_bgc_skip_deepbgc_1425:
    cond = ((condition_1373 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_skip_deepbgc"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_deepbgc_1425(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_deepbgc_1426(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_deepbgc_1426(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1425: typing.Union[str, None]
) -> Resparams_bgc_skip_deepbgc_1426:
    cond = ((condition_1373 == True) and (channel_1425 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1425)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_deepbgc_1426(
        res=out_channels.get("res", "")
    )


class Resconditional_params_bgc_skip_deepbgc_1427(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bgc_skip_deepbgc_1427(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1426: typing.Union[str, None]
) -> Resconditional_params_bgc_skip_deepbgc_1427:
    cond = ((condition_1373 == True) and (channel_1426 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1426)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bgc_skip_deepbgc_1427(condition=res)


class Resparams_bgc_skip_antismash_1379(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_antismash_1379(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None]
) -> Resparams_bgc_skip_antismash_1379:
    cond = ((condition_1373 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_skip_antismash"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_antismash_1379(
        res=out_channels.get("res", "")
    )


class Resparams_bgc_skip_antismash_1380(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_skip_antismash_1380(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1379: typing.Union[str, None]
) -> Resparams_bgc_skip_antismash_1380:
    cond = ((condition_1373 == True) and (channel_1379 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1379)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_skip_antismash_1380(
        res=out_channels.get("res", "")
    )


class Resconditional_params_bgc_skip_antismash_1381(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bgc_skip_antismash_1381(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1380: typing.Union[str, None]
) -> Resconditional_params_bgc_skip_antismash_1381:
    cond = ((condition_1373 == True) and (channel_1380 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1380)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bgc_skip_antismash_1381(condition=res)


class ResChannel_empty___1378(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1378(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None]
) -> ResChannel_empty___1378:
    cond = ((condition_1373 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1378(
        res=out_channels.get("res", "")
    )


class Res_params_annotation_tool____prodigal__1409(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_annotation_tool____prodigal__1409(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None]
) -> Res_params_annotation_tool____prodigal__1409:
    cond = ((condition_1373 == True) and (condition_1381 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"annotation_tool"}},"operation":"==","rightExpression":{"ConstantExpression":"prodigal"}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_annotation_tool____prodigal__1409(
        res=out_channels.get("res", "")
    )


class Res_params_annotation_tool____pyrodigal__1410(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_annotation_tool____pyrodigal__1410(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None]
) -> Res_params_annotation_tool____pyrodigal__1410:
    cond = ((condition_1373 == True) and (condition_1381 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"annotation_tool"}},"operation":"==","rightExpression":{"ConstantExpression":"pyrodigal"}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_annotation_tool____pyrodigal__1410(
        res=out_channels.get("res", "")
    )


class Res__params_annotation_tool____prodigal______params_annotation_tool_1411(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_annotation_tool____prodigal______params_annotation_tool_1411(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1409: typing.Union[str, None],
    channel_1410: typing.Union[str, None]
) -> Res__params_annotation_tool____prodigal______params_annotation_tool_1411:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1409 is not None) and (channel_1410 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1409), json.loads(channel_1410)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res__params_annotation_tool____prodigal______params_annotation_tool_1411(
        res=out_channels.get("res", "")
    )


class Res__params_annotation_tool____prodigal______params_annotation_tool_1412(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_annotation_tool____prodigal______params_annotation_tool_1412(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1411: typing.Union[str, None]
) -> Res__params_annotation_tool____prodigal______params_annotation_tool_1412:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1411 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1411)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res__params_annotation_tool____prodigal______params_annotation_tool_1412(
        res=out_channels.get("res", "")
    )


class Resconditional___params_annotation_tool____prodigal______params_annotation_tool_1413(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional___params_annotation_tool____prodigal______params_annotation_tool_1413(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1412: typing.Union[str, None]
) -> Resconditional___params_annotation_tool____prodigal______params_annotation_tool_1413:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1412 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1412)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional___params_annotation_tool____prodigal______params_annotation_tool_1413(condition=res)


@dataclass
class Dataclass_1124_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    gene_annotations: str


class Res_1124_pre(NamedTuple):
    default: typing.List[Dataclass_1124_pre]

@task(cache=True)
def pre_adapter_GUNZIP_PRODIGAL_GFF_1124_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    gene_annotations: typing.Union[str, None]
) -> Res_1124_pre:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (gene_annotations is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1124_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'gene_annotations': gene_annotations})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1124_pre(default=result)

class Respost_adapter_GUNZIP_PRODIGAL_GFF_1124_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1124_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_PRODIGAL_GFF_1124_post(
    default: List[Dataclass_1124_post]
) -> Respost_adapter_GUNZIP_PRODIGAL_GFF_1124_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_PRODIGAL_GFF_1124_post, default)


@task(cache=True)
def GUNZIP_PRODIGAL_GFF_1124(
    default: Dataclass_1124_pre
) -> Dataclass_1124_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.gene_annotations)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gunzip/main.nf", "alias": "GUNZIP_PRODIGAL_GFF", "name": "GUNZIP"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_PRODIGAL_GFF","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_PRODIGAL_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1124_post(
        gunzip=out_channels.get(f"gunzip", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResChannel_empty___1137(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1137(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None]
) -> ResChannel_empty___1137:
    cond = ((condition_1117 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1137(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_annotation_gff_1140(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_annotation_gff_1140(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    gunzip: typing.Union[str, None],
    channel_1137: typing.Union[str, None]
) -> ResMerge_ch_annotation_gff_1140:
    cond = True

    if cond:
        res = gunzip or channel_1137
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_annotation_gff_1140(
        res=res
    )


class Resfilter_1374(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_1374(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1140: typing.Union[str, None]
) -> Resfilter_1374:
    cond = ((condition_1373 == True) and (channel_1140 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1140)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}},"ifBlock":{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}},"method":"warn","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"Annotation of following sample produced produced an empty GFF file. AMP screening tools requiring this file will not be executed: $meta.id","strings":[{"ConstantExpression":"Annotation of following sample produced produced an empty GFF file. AMP screening tools requiring this file will not be executed: "},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}]}}]}}}},"labels":[]}},"elseBlock":{"EmptyStatement":null},"labels":[]}},{"ReturnStatement":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":["meta","file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfilter_1374(
        res=out_channels.get("res", "")
    )


class Resjoin_1414(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_1414(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1413: typing.Union[bool, None],
    channel_1101: typing.Union[str, None],
    channel_1374: typing.Union[str, None]
) -> Resjoin_1414:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1413 == True) and (channel_1101 is not None) and (channel_1374 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1101), json.loads(channel_1374)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ConstantExpression":0}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resjoin_1414(
        res=out_channels.get("res", "")
    )


class Resfilter_1415(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_1415(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1413: typing.Union[bool, None],
    channel_1414: typing.Union[str, None]
) -> Resfilter_1415:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1413 == True) and (channel_1414 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1414)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareLessThan","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"longest_contig"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_sampleminlength"}}]}}}}},"ifBlock":{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}},"method":"warn","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"[nf-core/funcscan] Sample does not have any contig reaching min. length threshold of --bgc_antismash_sampleminlength $params.bgc_antismash_sampleminlength. Antismash will not be run for sample: $meta.id.","strings":[{"ConstantExpression":"[nf-core/funcscan] Sample does not have any contig reaching min. length threshold of --bgc_antismash_sampleminlength "},{"ConstantExpression":". Antismash will not be run for sample: "},{"ConstantExpression":"."}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_sampleminlength"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}]}}]}}}},"labels":[]}},"elseBlock":{"EmptyStatement":null},"labels":[]}},{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareGreaterThanEqual","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"longest_contig"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_sampleminlength"}}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["compareLessThan","params","log","compareGreaterThanEqual"]},"labels":[]}},"parameters":["meta","fna","gff"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfilter_1415(
        res=out_channels.get("res", "")
    )


class ResmultiMap_1416(NamedTuple):
    fna: typing.Union[str, None]
    gff: typing.Union[str, None]

@task(cache=True)
def multiMap_1416(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1413: typing.Union[bool, None],
    channel_1415: typing.Union[str, None]
) -> ResmultiMap_1416:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1413 == True) and (channel_1415 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1415)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"multiMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"fna"}]},"labels":["fna"]}},{"ExpressionStatement":{"expression":{"ListExpression":[{"VariableExpression":"gff"}]},"labels":["gff"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fna","gff"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fna\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"fna\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gff\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"gff\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'fna': None, 'gff': None}

    return ResmultiMap_1416(
        fna=out_channels.get("fna", ""),
        gff=out_channels.get("gff", "")
    )


class Res_params_bgc_antismash_databases____params_bgc_antismash_installa_1382(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_bgc_antismash_databases____params_bgc_antismash_installa_1382(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None]
) -> Res_params_bgc_antismash_databases____params_bgc_antismash_installa_1382:
    cond = ((condition_1373 == True) and (condition_1381 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_databases"}},"operation":"&&","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_installationdirectory"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_bgc_antismash_databases____params_bgc_antismash_installa_1382(
        res=out_channels.get("res", "")
    )


class Res_params_bgc_antismash_databases____params_bgc_antismash_installa_1383(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_bgc_antismash_databases____params_bgc_antismash_installa_1383(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1382: typing.Union[str, None]
) -> Res_params_bgc_antismash_databases____params_bgc_antismash_installa_1383:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1382 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1382)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_bgc_antismash_databases____params_bgc_antismash_installa_1383(
        res=out_channels.get("res", "")
    )


class Resconditional__params_bgc_antismash_databases____params_bgc_antismash_installa_1384(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_bgc_antismash_databases____params_bgc_antismash_installa_1384(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1383: typing.Union[str, None]
) -> Resconditional__params_bgc_antismash_databases____params_bgc_antismash_installa_1384:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1383 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1383)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_bgc_antismash_databases____params_bgc_antismash_installa_1384(condition=res)


class ResChannel_fromPath_params_bgc_antismash_databases__1385(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_bgc_antismash_databases__1385(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None]
) -> ResChannel_fromPath_params_bgc_antismash_databases__1385:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_databases"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_bgc_antismash_databases__1385(
        res=out_channels.get("res", "")
    )


class Resfirst_1386(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1386(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1385: typing.Union[str, None]
) -> Resfirst_1386:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == True) and (channel_1385 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1385)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1386(
        res=out_channels.get("res", "")
    )


class Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1389(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def https___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1389(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None]
) -> Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1389:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"https://github.com/nf-core/test-datasets/raw/91bb8781c576967e23d2c5315dd4d43213575033/data/delete_me/antismash/css.tar.gz"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1389(
        res=out_channels.get("res", "")
    )


class Res_____ch_css_for_antismash__1392(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _____ch_css_for_antismash__1392(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1389: typing.Union[str, None]
) -> Res_____ch_css_for_antismash__1392:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1389 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1389)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_____ch_css_for_antismash__1392(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1393_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1392: str


class Res_1393_pre(NamedTuple):
    default: typing.List[Dataclass_1393_pre]

@task(cache=True)
def pre_adapter_UNTAR_CSS_1393_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1392: typing.Union[str, None]
) -> Res_1393_pre:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1392 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1393_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1392': channel_1392})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1393_pre(default=result)

class Respost_adapter_UNTAR_CSS_1393_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1393_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_CSS_1393_post(
    default: List[Dataclass_1393_post]
) -> Respost_adapter_UNTAR_CSS_1393_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_CSS_1393_post, default)


@task(cache=True)
def UNTAR_CSS_1393(
    default: Dataclass_1393_pre
) -> Dataclass_1393_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1392)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/untar/main.nf", "alias": "UNTAR_CSS", "name": "UNTAR"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_CSS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_CSS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_CSS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1393_post(
        untar=out_channels.get(f"untar", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmap_1401(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1401(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    untar: typing.Union[str, None]
) -> Resmap_1401:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (untar is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(untar)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1401(
        res=out_channels.get("res", "")
    )


class Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1390(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def https___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1390(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None]
) -> Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1390:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"https://github.com/nf-core/test-datasets/raw/91bb8781c576967e23d2c5315dd4d43213575033/data/delete_me/antismash/detection.tar.gz"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1390(
        res=out_channels.get("res", "")
    )


class Res_____ch_detection_for_antismash__1395(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _____ch_detection_for_antismash__1395(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1390: typing.Union[str, None]
) -> Res_____ch_detection_for_antismash__1395:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1390 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1390)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_____ch_detection_for_antismash__1395(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1396_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1395: str


class Res_1396_pre(NamedTuple):
    default: typing.List[Dataclass_1396_pre]

@task(cache=True)
def pre_adapter_UNTAR_DETECTION_1396_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1395: typing.Union[str, None]
) -> Res_1396_pre:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1395 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1396_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1395': channel_1395})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1396_pre(default=result)

class Respost_adapter_UNTAR_DETECTION_1396_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1396_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_DETECTION_1396_post(
    default: List[Dataclass_1396_post]
) -> Respost_adapter_UNTAR_DETECTION_1396_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_DETECTION_1396_post, default)


@task(cache=True)
def UNTAR_DETECTION_1396(
    default: Dataclass_1396_pre
) -> Dataclass_1396_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1395)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/untar/main.nf", "alias": "UNTAR_DETECTION", "name": "UNTAR"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_DETECTION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_DETECTION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_DETECTION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1396_post(
        untar=out_channels.get(f"untar", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmap_1402(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1402(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    untar: typing.Union[str, None]
) -> Resmap_1402:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (untar is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(untar)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1402(
        res=out_channels.get("res", "")
    )


class Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1391(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def https___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1391(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None]
) -> Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1391:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"https://github.com/nf-core/test-datasets/raw/91bb8781c576967e23d2c5315dd4d43213575033/data/delete_me/antismash/modules.tar.gz"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Reshttps___github_com_nf_core_test_datasets_raw_91bb8781c576967e23d_1391(
        res=out_channels.get("res", "")
    )


class Res_____ch_modules_for_antismash__1398(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _____ch_modules_for_antismash__1398(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1391: typing.Union[str, None]
) -> Res_____ch_modules_for_antismash__1398:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1391 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1391)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_____ch_modules_for_antismash__1398(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1399_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1398: str


class Res_1399_pre(NamedTuple):
    default: typing.List[Dataclass_1399_pre]

@task(cache=True)
def pre_adapter_UNTAR_MODULES_1399_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1398: typing.Union[str, None]
) -> Res_1399_pre:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1398 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1399_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1398': channel_1398})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1399_pre(default=result)

class Respost_adapter_UNTAR_MODULES_1399_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1399_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_MODULES_1399_post(
    default: List[Dataclass_1399_post]
) -> Respost_adapter_UNTAR_MODULES_1399_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_MODULES_1399_post, default)


@task(cache=True)
def UNTAR_MODULES_1399(
    default: Dataclass_1399_pre
) -> Dataclass_1399_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1398)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/untar/main.nf", "alias": "UNTAR_MODULES", "name": "UNTAR"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_MODULES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_MODULES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_MODULES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1399_post(
        untar=out_channels.get(f"untar", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmap_1403(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1403(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    untar: typing.Union[str, None]
) -> Resmap_1403:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (untar is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(untar)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1403(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1404_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1401: str
    channel_1402: str
    channel_1403: str


class Res_1404_pre(NamedTuple):
    default: typing.List[Dataclass_1404_pre]

@task(cache=True)
def pre_adapter_ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES_1404_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1401: typing.Union[str, None],
    channel_1402: typing.Union[str, None],
    channel_1403: typing.Union[str, None]
) -> Res_1404_pre:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1401 is not None) and (channel_1402 is not None) and (channel_1403 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1404_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1401': channel_1401, 'channel_1402': channel_1402, 'channel_1403': channel_1403})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1404_pre(default=result)

class Respost_adapter_ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES_1404_post(NamedTuple):
    database: typing.Union[str, None]
    antismash_dir: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1404_post:
    database: str
    antismash_dir: str
    versions: str

@task(cache=True)
def post_adapter_ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES_1404_post(
    default: List[Dataclass_1404_post]
) -> Respost_adapter_ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES_1404_post:
    return get_mapper_outputs(Respost_adapter_ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES_1404_post, default)


@task(cache=True)
def ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES_1404(
    default: Dataclass_1404_pre
) -> Dataclass_1404_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1401),json.loads(default.channel_1402),json.loads(default.channel_1403)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/antismash/antismashlitedownloaddatabases/main.nf", "alias": "ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES", "name": "ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"database\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"antismash_dir\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITEDOWNLOADDATABASES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1404_post(
        database=out_channels.get(f"database", ""),
        antismash_dir=out_channels.get(f"antismash_dir", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResMerge_ch_antismash_databases_1406(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_antismash_databases_1406(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1386: typing.Union[str, None],
    database: typing.Union[str, None]
) -> ResMerge_ch_antismash_databases_1406:
    cond = ((condition_1373 == True) and (condition_1381 == True))

    if cond:
        res = channel_1386 or database
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_antismash_databases_1406(
        res=res
    )


class ResChannel_fromPath_params_bgc_antismash_installationdirectory__1387(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_bgc_antismash_installationdirectory__1387(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None]
) -> ResChannel_fromPath_params_bgc_antismash_installationdirectory__1387:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_antismash_installationdirectory"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_bgc_antismash_installationdirectory__1387(
        res=out_channels.get("res", "")
    )


class Resfirst_1388(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1388(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1387: typing.Union[str, None]
) -> Resfirst_1388:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == True) and (channel_1387 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1387)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1388(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_antismash_directory_1407(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_antismash_directory_1407(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1388: typing.Union[str, None],
    antismash_dir: typing.Union[str, None]
) -> ResMerge_ch_antismash_directory_1407:
    cond = ((condition_1373 == True) and (condition_1381 == True))

    if cond:
        res = channel_1388 or antismash_dir
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_antismash_directory_1407(
        res=res
    )


@dataclass
class Dataclass_1417_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    fna: str
    channel_1406: str
    channel_1407: str
    gff: str


class Res_1417_pre(NamedTuple):
    default: typing.List[Dataclass_1417_pre]

@task(cache=True)
def pre_adapter_ANTISMASH_ANTISMASHLITE_1417_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1413: typing.Union[bool, None],
    fna: typing.Union[str, None],
    channel_1406: typing.Union[str, None],
    channel_1407: typing.Union[str, None],
    gff: typing.Union[str, None]
) -> Res_1417_pre:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1413 == True) and (fna is not None) and (channel_1406 is not None) and (channel_1407 is not None) and (gff is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1417_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'fna': fna, 'channel_1406': channel_1406, 'channel_1407': channel_1407, 'gff': gff})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1417_pre(default=result)

class Respost_adapter_ANTISMASH_ANTISMASHLITE_1417_post(NamedTuple):
    clusterblast_file: typing.Union[str, None]
    html_accessory_files: typing.Union[str, None]
    knownclusterblast_html: typing.Union[str, None]
    knownclusterblast_dir: typing.Union[str, None]
    knownclusterblast_txt: typing.Union[str, None]
    svg_files_clusterblast: typing.Union[str, None]
    svg_files_knownclusterblast: typing.Union[str, None]
    gbk_input: typing.Union[str, None]
    json_results: typing.Union[str, None]
    log: typing.Union[str, None]
    zip: typing.Union[str, None]
    gbk_results: typing.Union[str, None]
    clusterblastoutput: typing.Union[str, None]
    html: typing.Union[str, None]
    knownclusterblastoutput: typing.Union[str, None]
    json_sideloading: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1417_post:
    clusterblast_file: str
    html_accessory_files: str
    knownclusterblast_html: str
    knownclusterblast_dir: str
    knownclusterblast_txt: str
    svg_files_clusterblast: str
    svg_files_knownclusterblast: str
    gbk_input: str
    json_results: str
    log: str
    zip: str
    gbk_results: str
    clusterblastoutput: str
    html: str
    knownclusterblastoutput: str
    json_sideloading: str
    versions: str

@task(cache=True)
def post_adapter_ANTISMASH_ANTISMASHLITE_1417_post(
    default: List[Dataclass_1417_post]
) -> Respost_adapter_ANTISMASH_ANTISMASHLITE_1417_post:
    return get_mapper_outputs(Respost_adapter_ANTISMASH_ANTISMASHLITE_1417_post, default)


@task(cache=True)
def ANTISMASH_ANTISMASHLITE_1417(
    default: Dataclass_1417_pre
) -> Dataclass_1417_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.fna),json.loads(default.channel_1406),json.loads(default.channel_1407),json.loads(default.gff)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/antismash/antismashlite/main.nf", "alias": "ANTISMASH_ANTISMASHLITE", "name": "ANTISMASH_ANTISMASHLITE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"ANTISMASH_ANTISMASHLITE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"clusterblast_file\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html_accessory_files\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"knownclusterblast_html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"knownclusterblast_dir\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"knownclusterblast_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"svg_files_clusterblast\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"svg_files_knownclusterblast\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gbk_input\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gbk_results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"clusterblastoutput\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":12}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":13}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"knownclusterblastoutput\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":14}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_sideloading\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":15}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ANTISMASH_ANTISMASHLITE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":16}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1417_post(
        clusterblast_file=out_channels.get(f"clusterblast_file", ""),
        html_accessory_files=out_channels.get(f"html_accessory_files", ""),
        knownclusterblast_html=out_channels.get(f"knownclusterblast_html", ""),
        knownclusterblast_dir=out_channels.get(f"knownclusterblast_dir", ""),
        knownclusterblast_txt=out_channels.get(f"knownclusterblast_txt", ""),
        svg_files_clusterblast=out_channels.get(f"svg_files_clusterblast", ""),
        svg_files_knownclusterblast=out_channels.get(f"svg_files_knownclusterblast", ""),
        gbk_input=out_channels.get(f"gbk_input", ""),
        json_results=out_channels.get(f"json_results", ""),
        log=out_channels.get(f"log", ""),
        zip=out_channels.get(f"zip", ""),
        gbk_results=out_channels.get(f"gbk_results", ""),
        clusterblastoutput=out_channels.get(f"clusterblastoutput", ""),
        html=out_channels.get(f"html", ""),
        knownclusterblastoutput=out_channels.get(f"knownclusterblastoutput", ""),
        json_sideloading=out_channels.get(f"json_sideloading", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1419(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1419(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    knownclusterblast_dir: typing.Union[str, None],
    gbk_input: typing.Union[str, None]
) -> Resmix_1419:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (knownclusterblast_dir is not None) and (gbk_input is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(knownclusterblast_dir), json.loads(gbk_input)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1419(
        res=out_channels.get("res", "")
    )


class ResgroupTuple_1420(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_1420(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1419: typing.Union[str, None]
) -> ResgroupTuple_1420:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1419 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1419)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResgroupTuple_1420(
        res=out_channels.get("res", "")
    )


class Resmap_1421(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1421(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1420: typing.Union[str, None]
) -> Resmap_1421:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1420 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1420)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"files"},"method":"flatten","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","files"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1421(
        res=out_channels.get("res", "")
    )


class Resmix_1422(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1422(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1378: typing.Union[str, None],
    channel_1421: typing.Union[str, None]
) -> Resmix_1422:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1378 is not None) and (channel_1421 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1378), json.loads(channel_1421)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1422(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_bgcresults_for_combgc_1424(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bgcresults_for_combgc_1424(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1422: typing.Union[str, None],
    channel_1378: typing.Union[str, None]
) -> ResMerge_ch_bgcresults_for_combgc_1424:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1422 or channel_1378
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_bgcresults_for_combgc_1424(
        res=res
    )


class Resparams_bgc_deepbgc_database_1428(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bgc_deepbgc_database_1428(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None]
) -> Resparams_bgc_deepbgc_database_1428:
    cond = ((condition_1373 == True) and (condition_1427 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_deepbgc_database"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_bgc_deepbgc_database_1428(
        res=out_channels.get("res", "")
    )


class Resconditional_params_bgc_deepbgc_database_1429(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bgc_deepbgc_database_1429(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    channel_1428: typing.Union[str, None]
) -> Resconditional_params_bgc_deepbgc_database_1429:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (channel_1428 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1428)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bgc_deepbgc_database_1429(condition=res)


class ResChannel_fromPath_params_bgc_deepbgc_database__1430(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_bgc_deepbgc_database__1430(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    condition_1429: typing.Union[bool, None]
) -> ResChannel_fromPath_params_bgc_deepbgc_database__1430:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (condition_1429 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_deepbgc_database"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_bgc_deepbgc_database__1430(
        res=out_channels.get("res", "")
    )


class Resfirst_1431(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1431(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    condition_1429: typing.Union[bool, None],
    channel_1430: typing.Union[str, None]
) -> Resfirst_1431:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (condition_1429 == True) and (channel_1430 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1430)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1431(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1432_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir


class Res_1432_pre(NamedTuple):
    default: typing.List[Dataclass_1432_pre]

@task(cache=True)
def pre_adapter_DEEPBGC_DOWNLOAD_1432_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    condition_1429: typing.Union[bool, None]
) -> Res_1432_pre:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (condition_1429 == False))

    if cond:
        result = get_mapper_inputs(Dataclass_1432_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1432_pre(default=result)

class Respost_adapter_DEEPBGC_DOWNLOAD_1432_post(NamedTuple):
    db: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1432_post:
    db: str
    versions: str

@task(cache=True)
def post_adapter_DEEPBGC_DOWNLOAD_1432_post(
    default: List[Dataclass_1432_post]
) -> Respost_adapter_DEEPBGC_DOWNLOAD_1432_post:
    return get_mapper_outputs(Respost_adapter_DEEPBGC_DOWNLOAD_1432_post, default)


@task(cache=True)
def DEEPBGC_DOWNLOAD_1432(
    default: Dataclass_1432_pre
) -> Dataclass_1432_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = []

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/deepbgc/download/main.nf", "alias": "DEEPBGC_DOWNLOAD", "name": "DEEPBGC_DOWNLOAD"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DEEPBGC_DOWNLOAD","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"db\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_DOWNLOAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_DOWNLOAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1432_post(
        db=out_channels.get(f"db", ""),
        versions=out_channels.get(f"versions", "")
    )


class ResMerge_ch_deepbgc_database_1434(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_deepbgc_database_1434(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    channel_1431: typing.Union[str, None],
    db: typing.Union[str, None]
) -> ResMerge_ch_deepbgc_database_1434:
    cond = ((condition_1373 == True) and (condition_1427 == True))

    if cond:
        res = channel_1431 or db
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_deepbgc_database_1434(
        res=res
    )


@dataclass
class Dataclass_1436_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str
    channel_1434: str


class Res_1436_pre(NamedTuple):
    default: typing.List[Dataclass_1436_pre]

@task(cache=True)
def pre_adapter_DEEPBGC_PIPELINE_1436_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    channel_1101: typing.Union[str, None],
    channel_1434: typing.Union[str, None]
) -> Res_1436_pre:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (channel_1101 is not None) and (channel_1434 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1436_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101, 'channel_1434': channel_1434})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1436_pre(default=result)

class Respost_adapter_DEEPBGC_PIPELINE_1436_post(NamedTuple):
    readme: typing.Union[str, None]
    log: typing.Union[str, None]
    json: typing.Union[str, None]
    bgc_gbk: typing.Union[str, None]
    bgc_tsv: typing.Union[str, None]
    full_gbk: typing.Union[str, None]
    pfam_tsv: typing.Union[str, None]
    bgc_png: typing.Union[str, None]
    pr_png: typing.Union[str, None]
    roc_png: typing.Union[str, None]
    score_png: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1436_post:
    readme: str
    log: str
    json: str
    bgc_gbk: str
    bgc_tsv: str
    full_gbk: str
    pfam_tsv: str
    bgc_png: str
    pr_png: str
    roc_png: str
    score_png: str
    versions: str

@task(cache=True)
def post_adapter_DEEPBGC_PIPELINE_1436_post(
    default: List[Dataclass_1436_post]
) -> Respost_adapter_DEEPBGC_PIPELINE_1436_post:
    return get_mapper_outputs(Respost_adapter_DEEPBGC_PIPELINE_1436_post, default)


@task(cache=True)
def DEEPBGC_PIPELINE_1436(
    default: Dataclass_1436_pre
) -> Dataclass_1436_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101),json.loads(default.channel_1434)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/deepbgc/pipeline/main.nf", "alias": "DEEPBGC_PIPELINE", "name": "DEEPBGC_PIPELINE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DEEPBGC_PIPELINE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"readme\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bgc_gbk\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bgc_tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"full_gbk\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pfam_tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bgc_png\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pr_png\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"roc_png\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"score_png\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPBGC_PIPELINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1436_post(
        readme=out_channels.get(f"readme", ""),
        log=out_channels.get(f"log", ""),
        json=out_channels.get(f"json", ""),
        bgc_gbk=out_channels.get(f"bgc_gbk", ""),
        bgc_tsv=out_channels.get(f"bgc_tsv", ""),
        full_gbk=out_channels.get(f"full_gbk", ""),
        pfam_tsv=out_channels.get(f"pfam_tsv", ""),
        bgc_png=out_channels.get(f"bgc_png", ""),
        pr_png=out_channels.get(f"pr_png", ""),
        roc_png=out_channels.get(f"roc_png", ""),
        score_png=out_channels.get(f"score_png", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1438(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1438(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    channel_1424: typing.Union[str, None],
    bgc_tsv: typing.Union[str, None]
) -> Resmix_1438:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (channel_1424 is not None) and (bgc_tsv is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1424), json.loads(bgc_tsv)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1438(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_bgcresults_for_combgc_1439(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bgcresults_for_combgc_1439(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1438: typing.Union[str, None],
    channel_1424: typing.Union[str, None]
) -> ResMerge_ch_bgcresults_for_combgc_1439:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1438 or channel_1424
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_bgcresults_for_combgc_1439(
        res=res
    )


class ResgroupTuple_1444(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_1444(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> ResgroupTuple_1444:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (channel_1101 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1101)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResgroupTuple_1444(
        res=out_channels.get("res", "")
    )


class ResmultiMap_1445(NamedTuple):
    fna: typing.Union[str, None]

@task(cache=True)
def multiMap_1445(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    channel_1444: typing.Union[str, None]
) -> ResmultiMap_1445:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (channel_1444 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1444)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"multiMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}},{"ListExpression":[]}]},"labels":["fna"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fna\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"fna\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'fna': None}

    return ResmultiMap_1445(
        fna=out_channels.get("fna", "")
    )


@dataclass
class Dataclass_1446_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    fna: str


class Res_1446_pre(NamedTuple):
    default: typing.List[Dataclass_1446_pre]

@task(cache=True)
def pre_adapter_GECCO_RUN_1446_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    fna: typing.Union[str, None]
) -> Res_1446_pre:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (fna is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1446_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'fna': fna})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1446_pre(default=result)

class Respost_adapter_GECCO_RUN_1446_post(NamedTuple):
    genes: typing.Union[str, None]
    features: typing.Union[str, None]
    clusters: typing.Union[str, None]
    gbk: typing.Union[str, None]
    json: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1446_post:
    genes: str
    features: str
    clusters: str
    gbk: str
    json: str
    versions: str

@task(cache=True)
def post_adapter_GECCO_RUN_1446_post(
    default: List[Dataclass_1446_post]
) -> Respost_adapter_GECCO_RUN_1446_post:
    return get_mapper_outputs(Respost_adapter_GECCO_RUN_1446_post, default)


@task(cache=True)
def GECCO_RUN_1446(
    default: Dataclass_1446_pre
) -> Dataclass_1446_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.fna)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/gecco/run/main.nf", "alias": "GECCO_RUN", "name": "GECCO_RUN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GECCO_RUN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"genes\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GECCO_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"features\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GECCO_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"clusters\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GECCO_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gbk\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GECCO_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GECCO_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GECCO_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1446_post(
        genes=out_channels.get(f"genes", ""),
        features=out_channels.get(f"features", ""),
        clusters=out_channels.get(f"clusters", ""),
        gbk=out_channels.get(f"gbk", ""),
        json=out_channels.get(f"json", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1448(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1448(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    gbk: typing.Union[str, None],
    clusters: typing.Union[str, None]
) -> Resmix_1448:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (gbk is not None) and (clusters is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(gbk), json.loads(clusters)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1448(
        res=out_channels.get("res", "")
    )


class ResgroupTuple_1449(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_1449(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    channel_1448: typing.Union[str, None]
) -> ResgroupTuple_1449:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (channel_1448 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1448)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResgroupTuple_1449(
        res=out_channels.get("res", "")
    )


class Resmap_1450(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1450(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    channel_1449: typing.Union[str, None]
) -> Resmap_1450:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (channel_1449 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1449)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"files"},"method":"flatten","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","files"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1450(
        res=out_channels.get("res", "")
    )


class Resmix_1451(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1451(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    channel_1439: typing.Union[str, None],
    channel_1450: typing.Union[str, None]
) -> Resmix_1451:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (channel_1439 is not None) and (channel_1450 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1439), json.loads(channel_1450)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1451(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_bgcresults_for_combgc_1452(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bgcresults_for_combgc_1452(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1451: typing.Union[str, None],
    channel_1439: typing.Union[str, None]
) -> ResMerge_ch_bgcresults_for_combgc_1452:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1451 or channel_1439
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_bgcresults_for_combgc_1452(
        res=res
    )


@dataclass
class Dataclass_1467_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1452: str


class Res_1467_pre(NamedTuple):
    default: typing.List[Dataclass_1467_pre]

@task(cache=True)
def pre_adapter_COMBGC_1467_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1452: typing.Union[str, None]
) -> Res_1467_pre:
    cond = ((condition_1373 == True) and (channel_1452 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1467_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1452': channel_1452})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1467_pre(default=result)

class Respost_adapter_COMBGC_1467_post(NamedTuple):
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1467_post:
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_COMBGC_1467_post(
    default: List[Dataclass_1467_post]
) -> Respost_adapter_COMBGC_1467_post:
    return get_mapper_outputs(Respost_adapter_COMBGC_1467_post, default)


@task(cache=True)
def COMBGC_1467(
    default: Dataclass_1467_pre
) -> Dataclass_1467_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1452)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/local/combgc.nf", "alias": "COMBGC", "name": "COMBGC"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"COMBGC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"COMBGC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"COMBGC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1467_post(
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmap_1468(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1468(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    tsv: typing.Union[str, None]
) -> Resmap_1468:
    cond = ((condition_1373 == True) and (tsv is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(tsv)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1468(
        res=out_channels.get("res", "")
    )


class RescollectFile_1469(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_1469(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1468: typing.Union[str, None]
) -> RescollectFile_1469:
    cond = ((condition_1373 == True) and (channel_1468 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1468)]

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"combgc_complete_summary.tsv"}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"storeDir"},"valueExpression":{"GStringExpression":{"verbatimText":"$params.outdir/reports/combgc","strings":[{"ConstantExpression":""},{"ConstantExpression":"/reports/combgc"}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"outdir"}}]}}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"keepHeader"},"valueExpression":{"ConstantExpression":true}}}]}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RescollectFile_1469(
        res=out_channels.get("res", "")
    )


class Res_params_annotation_tool____prokka__1478(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_annotation_tool____prokka__1478(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Res_params_annotation_tool____prokka__1478:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"annotation_tool"}},"operation":"==","rightExpression":{"ConstantExpression":"prokka"}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_annotation_tool____prokka__1478(
        res=out_channels.get("res", "")
    )


class Res_params_annotation_tool____prokka__1479(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_annotation_tool____prokka__1479(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1478: typing.Union[str, None]
) -> Res_params_annotation_tool____prokka__1479:
    cond = ((channel_1478 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1478)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_annotation_tool____prokka__1479(
        res=out_channels.get("res", "")
    )


class Resconditional__params_annotation_tool____prokka__1480(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_annotation_tool____prokka__1480(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1479: typing.Union[str, None]
) -> Resconditional__params_annotation_tool____prokka__1480:
    cond = ((channel_1479 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1479)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_annotation_tool____prokka__1480(condition=res)


class ResChannel_empty___1475(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1475(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> ResChannel_empty___1475:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1475(
        res=out_channels.get("res", "")
    )


class Resparams_run_arg_screening_1213(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_run_arg_screening_1213(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_run_arg_screening_1213:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"run_arg_screening"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_run_arg_screening_1213(
        res=out_channels.get("res", "")
    )


class Resconditional_params_run_arg_screening_1214(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_run_arg_screening_1214(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1213: typing.Union[str, None]
) -> Resconditional_params_run_arg_screening_1214:
    cond = ((channel_1213 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1213)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_run_arg_screening_1214(condition=res)


class ResChannel_empty___1091(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1091(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> ResChannel_empty___1091:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1091(
        res=out_channels.get("res", "")
    )


class Resmix_1096(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1096(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1091: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1096:
    cond = ((channel_1091 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1091), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1096(
        res=out_channels.get("res", "")
    )


class Resmix_1099(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1099(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1096: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1099:
    cond = ((channel_1096 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1096), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1099(
        res=out_channels.get("res", "")
    )


class Resmix_1125(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1125(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    channel_1099: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1125:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (channel_1099 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1099), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1125(
        res=out_channels.get("res", "")
    )


class Resmix_1131(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1131(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    condition_1129: typing.Union[bool, None],
    channel_1125: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1131:
    cond = ((condition_1117 == True) and (condition_1120 == True) and (condition_1129 == True) and (channel_1125 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1125), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1131(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1133(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1133(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    condition_1120: typing.Union[bool, None],
    channel_1131: typing.Union[str, None],
    channel_1125: typing.Union[str, None]
) -> ResMerge_ch_versions_1133:
    cond = ((condition_1117 == True) and (condition_1120 == True))

    if cond:
        res = channel_1131 or channel_1125
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1133(
        res=res
    )


class ResMerge_ch_versions_1134(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1134(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1117: typing.Union[bool, None],
    channel_1133: typing.Union[str, None],
    channel_1099: typing.Union[str, None]
) -> ResMerge_ch_versions_1134:
    cond = ((condition_1117 == True))

    if cond:
        res = channel_1133 or channel_1099
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1134(
        res=res
    )


class ResMerge_ch_versions_1143(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1143(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1134: typing.Union[str, None],
    channel_1099: typing.Union[str, None]
) -> ResMerge_ch_versions_1143:
    cond = True

    if cond:
        res = channel_1134 or channel_1099
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1143(
        res=res
    )


class ResChannel_empty___1147(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1147(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None]
) -> ResChannel_empty___1147:
    cond = ((condition_1145 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1147(
        res=out_channels.get("res", "")
    )


class Resmix_1155(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1155(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1153: typing.Union[bool, None],
    channel_1147: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1155:
    cond = ((condition_1145 == True) and (condition_1153 == True) and (channel_1147 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1147), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1155(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1158(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1158(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1155: typing.Union[str, None],
    channel_1147: typing.Union[str, None]
) -> ResMerge_ch_versions_1158:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1155 or channel_1147
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1158(
        res=res
    )


class Resmix_1163(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1163(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1158: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1163:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1158 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1158), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1163(
        res=out_channels.get("res", "")
    )


class Resmix_1166(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1166(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1163: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1166:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1163 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1163), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1166(
        res=out_channels.get("res", "")
    )


class Resmix_1167(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1167(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1161: typing.Union[bool, None],
    channel_1166: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1167:
    cond = ((condition_1145 == True) and (condition_1161 == True) and (channel_1166 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1166), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1167(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1174(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1174(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1167: typing.Union[str, None],
    channel_1158: typing.Union[str, None]
) -> ResMerge_ch_versions_1174:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1167 or channel_1158
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1174(
        res=res
    )


class Resmix_1179(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1179(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1177: typing.Union[bool, None],
    channel_1174: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1179:
    cond = ((condition_1145 == True) and (condition_1177 == True) and (channel_1174 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1174), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1179(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1182(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1182(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1179: typing.Union[str, None],
    channel_1174: typing.Union[str, None]
) -> ResMerge_ch_versions_1182:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1179 or channel_1174
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1182(
        res=res
    )


class ResChannel_fromPath__checkIfExists_true___params_amp_hmmsearch_mode_1188(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_amp_hmmsearch_mode_1188(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    condition_1187: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_amp_hmmsearch_mode_1188:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (condition_1187 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_hmmsearch_models"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_amp_hmmsearch_mode_1188(
        res=out_channels.get("res", "")
    )


class Resmap_1190(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1190(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    channel_1188: typing.Union[str, None]
) -> Resmap_1190:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (channel_1188 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1188)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"=","rightExpression":{"MapExpression":[]}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}},"operation":"=","rightExpression":{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"file"},"property":"extension"}},{"ConstantExpression":"gz"}]}}}}},"trueExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"file"},"property":"name"}},"operation":"-","rightExpression":{"ConstantExpression":".hmm.gz"}}},"falseExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"file"},"property":"name"}},"operation":"-","rightExpression":{"ConstantExpression":".hmm"}}}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"file"}]}}],"scope":{"declaredVariables":["meta"],"referencedClassVariables":["compareEqual"]},"labels":[]}},"parameters":["file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1190(
        res=out_channels.get("res", "")
    )


class Rescombine_1191(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_1191(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    channel_1146: typing.Union[str, None],
    channel_1190: typing.Union[str, None]
) -> Rescombine_1191:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (channel_1146 is not None) and (channel_1190 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1146), json.loads(channel_1190)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescombine_1191(
        res=out_channels.get("res", "")
    )


class Resmap_1192(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1192(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    channel_1191: typing.Union[str, None]
) -> Resmap_1192:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (channel_1191 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1191)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"=","rightExpression":{"MapExpression":[]}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_faa"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"[","rightExpression":{"ConstantExpression":"hmm_id"}}},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_hmm"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta_new"},{"VariableExpression":"hmm"},{"VariableExpression":"faa"},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_hmmsearch_savealignments"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_hmmsearch_savetargets"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"amp_hmmsearch_savedomains"}}]}}],"scope":{"declaredVariables":["meta_new"],"referencedClassVariables":["params"]},"labels":[]}},"parameters":["meta_faa","faa","meta_hmm","hmm"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1192(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1193_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1192: str


class Res_1193_pre(NamedTuple):
    default: typing.List[Dataclass_1193_pre]

@task(cache=True)
def pre_adapter_AMP_HMMER_HMMSEARCH_1193_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    channel_1192: typing.Union[str, None]
) -> Res_1193_pre:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (channel_1192 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1193_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1192': channel_1192})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1193_pre(default=result)

class Respost_adapter_AMP_HMMER_HMMSEARCH_1193_post(NamedTuple):
    output: typing.Union[str, None]
    alignments: typing.Union[str, None]
    target_summary: typing.Union[str, None]
    domain_summary: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1193_post:
    output: str
    alignments: str
    target_summary: str
    domain_summary: str
    versions: str

@task(cache=True)
def post_adapter_AMP_HMMER_HMMSEARCH_1193_post(
    default: List[Dataclass_1193_post]
) -> Respost_adapter_AMP_HMMER_HMMSEARCH_1193_post:
    return get_mapper_outputs(Respost_adapter_AMP_HMMER_HMMSEARCH_1193_post, default)


@task(cache=True)
def AMP_HMMER_HMMSEARCH_1193(
    default: Dataclass_1193_pre
) -> Dataclass_1193_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1192)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hmmer/hmmsearch/main.nf", "alias": "AMP_HMMER_HMMSEARCH", "name": "HMMER_HMMSEARCH"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"AMP_HMMER_HMMSEARCH","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"output\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMP_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"alignments\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMP_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"target_summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMP_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"domain_summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMP_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMP_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1193_post(
        output=out_channels.get(f"output", ""),
        alignments=out_channels.get(f"alignments", ""),
        target_summary=out_channels.get(f"target_summary", ""),
        domain_summary=out_channels.get(f"domain_summary", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1194(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1194(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    condition_1185: typing.Union[bool, None],
    channel_1182: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1194:
    cond = ((condition_1145 == True) and (condition_1185 == True) and (channel_1182 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1182), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1194(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1195(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1195(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1194: typing.Union[str, None],
    channel_1182: typing.Union[str, None]
) -> ResMerge_ch_versions_1195:
    cond = ((condition_1145 == True))

    if cond:
        res = channel_1194 or channel_1182
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1195(
        res=res
    )


class Resmix_1211(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1211(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1145: typing.Union[bool, None],
    channel_1143: typing.Union[str, None],
    channel_1195: typing.Union[str, None]
) -> Resmix_1211:
    cond = ((condition_1145 == True) and (channel_1143 is not None) and (channel_1195 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1143), json.loads(channel_1195)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1211(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1212(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1212(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1211: typing.Union[str, None],
    channel_1143: typing.Union[str, None]
) -> ResMerge_ch_versions_1212:
    cond = True

    if cond:
        res = channel_1211 or channel_1143
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1212(
        res=res
    )


class Resparams_arg_skip_deeparg_1215(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1215(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None]
) -> Resparams_arg_skip_deeparg_1215:
    cond = ((condition_1214 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_deeparg"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1215(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_deeparg_1216(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_deeparg_1216(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    channel_1215: typing.Union[str, None]
) -> Resconditional_params_arg_skip_deeparg_1216:
    cond = ((condition_1214 == True) and (channel_1215 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1215)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_deeparg_1216(condition=res)


class Resparams_arg_skip_abricate_1279(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_abricate_1279(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_abricate_1279:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_abricate"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_abricate_1279(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_abricate_1280(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_abricate_1280(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1279: typing.Union[str, None]
) -> Resparams_arg_skip_abricate_1280:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1279 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1279)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_abricate_1280(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_abricate_1281(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_abricate_1281(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1280: typing.Union[str, None]
) -> Resconditional_params_arg_skip_abricate_1281:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1280 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1280)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_abricate_1281(condition=res)


class Resparams_arg_skip_deeparg_1267(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1267(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_deeparg_1267:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_deeparg"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1267(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_deeparg_1268(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1268(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1267: typing.Union[str, None]
) -> Resparams_arg_skip_deeparg_1268:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1267 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1267)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1268(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_deeparg_1269(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_deeparg_1269(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1268: typing.Union[str, None]
) -> Resconditional_params_arg_skip_deeparg_1269:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1268 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1268)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_deeparg_1269(condition=res)


class Resparams_arg_skip_rgi_1251(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_rgi_1251(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_rgi_1251:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_rgi"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_rgi_1251(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_rgi_1252(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_rgi_1252(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1251: typing.Union[str, None]
) -> Resparams_arg_skip_rgi_1252:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1251 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1251)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_rgi_1252(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_rgi_1253(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_rgi_1253(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1252: typing.Union[str, None]
) -> Resconditional_params_arg_skip_rgi_1253:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1252 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1252)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_rgi_1253(condition=res)


class Resparams_arg_skip_fargene_1236(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_fargene_1236(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_fargene_1236:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_fargene"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_fargene_1236(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_fargene_1237(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_fargene_1237(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1236: typing.Union[str, None]
) -> Resparams_arg_skip_fargene_1237:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1236 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1236)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_fargene_1237(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_fargene_1238(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_fargene_1238(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1237: typing.Union[str, None]
) -> Resconditional_params_arg_skip_fargene_1238:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1237 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1237)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_fargene_1238(condition=res)


class Resparams_arg_skip_amrfinderplus_1226(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_amrfinderplus_1226(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_amrfinderplus_1226:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_amrfinderplus"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_amrfinderplus_1226(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_amrfinderplus_1227(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_amrfinderplus_1227(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1226: typing.Union[str, None]
) -> Resparams_arg_skip_amrfinderplus_1227:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1226 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1226)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_amrfinderplus_1227(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_amrfinderplus_1228(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_amrfinderplus_1228(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1227: typing.Union[str, None]
) -> Resconditional_params_arg_skip_amrfinderplus_1228:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1227 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1227)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_amrfinderplus_1228(condition=res)


class ResChannel_empty___1218(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1218(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> ResChannel_empty___1218:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1218(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_amrfinderplus_1220(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_amrfinderplus_1220(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_amrfinderplus_1220:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_amrfinderplus"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_amrfinderplus_1220(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1221(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1221(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1220: typing.Union[str, None]
) -> Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1221:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1220 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1220)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_amrfinderplus_db"}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1221(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1222(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1222(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1221: typing.Union[str, None]
) -> Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1222:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1221 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1221)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1222(
        res=out_channels.get("res", "")
    )


class Resconditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1223(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1223(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1222: typing.Union[str, None]
) -> Resconditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1223:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1222 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1222)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1223(condition=res)


class ResChannel_fromPath_params_arg_amrfinderplus_db__1224(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_arg_amrfinderplus_db__1224(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1223: typing.Union[bool, None]
) -> ResChannel_fromPath_params_arg_amrfinderplus_db__1224:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1223 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_amrfinderplus_db"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_arg_amrfinderplus_db__1224(
        res=out_channels.get("res", "")
    )


class Resfirst_1225(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1225(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1223: typing.Union[bool, None],
    channel_1224: typing.Union[str, None]
) -> Resfirst_1225:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1223 == True) and (channel_1224 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1224)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1225(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1229_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str
    channel_1225: str


class Res_1229_pre(NamedTuple):
    default: typing.List[Dataclass_1229_pre]

@task(cache=True)
def pre_adapter_AMRFINDERPLUS_RUN_1229_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1228: typing.Union[bool, None],
    channel_1101: typing.Union[str, None],
    channel_1225: typing.Union[str, None]
) -> Res_1229_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1228 == True) and (channel_1101 is not None) and (channel_1225 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1229_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101, 'channel_1225': channel_1225})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1229_pre(default=result)

class Respost_adapter_AMRFINDERPLUS_RUN_1229_post(NamedTuple):
    report: typing.Union[str, None]
    mutation_report: typing.Union[str, None]
    versions: typing.Union[str, None]
    tool_version: typing.Union[str, None]
    db_version: typing.Union[str, None]

@dataclass
class Dataclass_1229_post:
    report: str
    mutation_report: str
    versions: str
    tool_version: str
    db_version: str

@task(cache=True)
def post_adapter_AMRFINDERPLUS_RUN_1229_post(
    default: List[Dataclass_1229_post]
) -> Respost_adapter_AMRFINDERPLUS_RUN_1229_post:
    return get_mapper_outputs(Respost_adapter_AMRFINDERPLUS_RUN_1229_post, default)


@task(cache=True)
def AMRFINDERPLUS_RUN_1229(
    default: Dataclass_1229_pre
) -> Dataclass_1229_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101),json.loads(default.channel_1225)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/amrfinderplus/run/main.nf", "alias": "AMRFINDERPLUS_RUN", "name": "AMRFINDERPLUS_RUN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"AMRFINDERPLUS_RUN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mutation_report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tool_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"db_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1229_post(
        report=out_channels.get(f"report", ""),
        mutation_report=out_channels.get(f"mutation_report", ""),
        versions=out_channels.get(f"versions", ""),
        tool_version=out_channels.get(f"tool_version", ""),
        db_version=out_channels.get(f"db_version", "")
    )


class Resmix_1230(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1230(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1228: typing.Union[bool, None],
    channel_1218: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1230:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1228 == True) and (channel_1218 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1218), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1230(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1231_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    report: str
    tool_version: str
    db_version: str


class Res_1231_pre(NamedTuple):
    default: typing.List[Dataclass_1231_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_AMRFINDERPLUS_1231_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1228: typing.Union[bool, None],
    report: typing.Union[str, None],
    tool_version: typing.Union[str, None],
    db_version: typing.Union[str, None]
) -> Res_1231_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1228 == True) and (report is not None) and (tool_version is not None) and (db_version is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1231_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'report': report, 'tool_version': tool_version, 'db_version': db_version})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1231_pre(default=result)

class Respost_adapter_HAMRONIZATION_AMRFINDERPLUS_1231_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1231_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_AMRFINDERPLUS_1231_post(
    default: List[Dataclass_1231_post]
) -> Respost_adapter_HAMRONIZATION_AMRFINDERPLUS_1231_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_AMRFINDERPLUS_1231_post, default)


@task(cache=True)
def HAMRONIZATION_AMRFINDERPLUS_1231(
    default: Dataclass_1231_pre
) -> Dataclass_1231_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.report),json.loads(default.tool_version),json.loads(default.db_version)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/amrfinderplus/main.nf", "alias": "HAMRONIZATION_AMRFINDERPLUS", "name": "HAMRONIZATION_AMRFINDERPLUS"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_AMRFINDERPLUS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_AMRFINDERPLUS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_AMRFINDERPLUS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_AMRFINDERPLUS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1231_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1232(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1232(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1228: typing.Union[bool, None],
    channel_1230: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1232:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1228 == True) and (channel_1230 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1230), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1232(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1235(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1235(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1232: typing.Union[str, None],
    channel_1218: typing.Union[str, None]
) -> ResMerge_ch_versions_1235:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1232 or channel_1218
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1235(
        res=res
    )


class ResChannel_fromList_params_arg_fargene_hmmmodel_tokenize_____1239(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromList_params_arg_fargene_hmmmodel_tokenize_____1239(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None]
) -> ResChannel_fromList_params_arg_fargene_hmmmodel_tokenize_____1239:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromList","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_fargene_hmmmodel"}},"method":"tokenize","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":","}]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromList_params_arg_fargene_hmmmodel_tokenize_____1239(
        res=out_channels.get("res", "")
    )


class Rescombine_1240(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_1240(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1101: typing.Union[str, None],
    channel_1239: typing.Union[str, None]
) -> Rescombine_1240:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1101 is not None) and (channel_1239 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1101), json.loads(channel_1239)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescombine_1240(
        res=out_channels.get("res", "")
    )


class Resmap_1241(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1241(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1240: typing.Union[str, None]
) -> Resmap_1241:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1240 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1240)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"meta"},"method":"clone","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"[","rightExpression":{"ConstantExpression":"hmm_class"}}},"operation":"=","rightExpression":{"VariableExpression":"hmm_class"}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta_new"},{"VariableExpression":"contigs"},{"VariableExpression":"hmm_class"}]}}],"scope":{"declaredVariables":["meta_new"],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","contigs","hmm_class"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1241(
        res=out_channels.get("res", "")
    )


class ResmultiMap_1242(NamedTuple):
    contigs: typing.Union[str, None]
    hmmclass: typing.Union[str, None]

@task(cache=True)
def multiMap_1242(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1241: typing.Union[str, None]
) -> ResmultiMap_1242:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1241 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1241)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"multiMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}]},"labels":["contigs"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":2}}},"labels":["hmmclass"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"contigs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"contigs\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"hmmclass\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"hmmclass\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'contigs': None, 'hmmclass': None}

    return ResmultiMap_1242(
        contigs=out_channels.get("contigs", ""),
        hmmclass=out_channels.get("hmmclass", "")
    )


@dataclass
class Dataclass_1243_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    contigs: str
    hmmclass: str


class Res_1243_pre(NamedTuple):
    default: typing.List[Dataclass_1243_pre]

@task(cache=True)
def pre_adapter_FARGENE_1243_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    contigs: typing.Union[str, None],
    hmmclass: typing.Union[str, None]
) -> Res_1243_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (contigs is not None) and (hmmclass is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1243_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'contigs': contigs, 'hmmclass': hmmclass})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1243_pre(default=result)

class Respost_adapter_FARGENE_1243_post(NamedTuple):
    log: typing.Union[str, None]
    txt: typing.Union[str, None]
    hmm: typing.Union[str, None]
    orfs: typing.Union[str, None]
    orfs_amino: typing.Union[str, None]
    contigs: typing.Union[str, None]
    contigs_pept: typing.Union[str, None]
    filtered: typing.Union[str, None]
    filtered_pept: typing.Union[str, None]
    fragments: typing.Union[str, None]
    trimmed: typing.Union[str, None]
    spades: typing.Union[str, None]
    metagenome: typing.Union[str, None]
    tmp: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1243_post:
    log: str
    txt: str
    hmm: str
    orfs: str
    orfs_amino: str
    contigs: str
    contigs_pept: str
    filtered: str
    filtered_pept: str
    fragments: str
    trimmed: str
    spades: str
    metagenome: str
    tmp: str
    versions: str

@task(cache=True)
def post_adapter_FARGENE_1243_post(
    default: List[Dataclass_1243_post]
) -> Respost_adapter_FARGENE_1243_post:
    return get_mapper_outputs(Respost_adapter_FARGENE_1243_post, default)


@task(cache=True)
def FARGENE_1243(
    default: Dataclass_1243_pre
) -> Dataclass_1243_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.contigs),json.loads(default.hmmclass)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/fargene/main.nf", "alias": "FARGENE", "name": "FARGENE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FARGENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"hmm\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"orfs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"orfs_amino\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"contigs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"contigs_pept\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"filtered\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"filtered_pept\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fragments\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"trimmed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"spades\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"metagenome\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":12}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tmp\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":13}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":14}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1243_post(
        log=out_channels.get(f"log", ""),
        txt=out_channels.get(f"txt", ""),
        hmm=out_channels.get(f"hmm", ""),
        orfs=out_channels.get(f"orfs", ""),
        orfs_amino=out_channels.get(f"orfs_amino", ""),
        contigs=out_channels.get(f"contigs", ""),
        contigs_pept=out_channels.get(f"contigs_pept", ""),
        filtered=out_channels.get(f"filtered", ""),
        filtered_pept=out_channels.get(f"filtered_pept", ""),
        fragments=out_channels.get(f"fragments", ""),
        trimmed=out_channels.get(f"trimmed", ""),
        spades=out_channels.get(f"spades", ""),
        metagenome=out_channels.get(f"metagenome", ""),
        tmp=out_channels.get(f"tmp", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1244(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1244(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1235: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1244:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1235 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1235), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1244(
        res=out_channels.get("res", "")
    )


class Restranspose_1245(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def transpose_1245(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    hmm: typing.Union[str, None]
) -> Restranspose_1245:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (hmm is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(hmm)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"transpose","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Restranspose_1245(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1246_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1245: str


class Res_1246_pre(NamedTuple):
    default: typing.List[Dataclass_1246_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_FARGENE_1246_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1245: typing.Union[str, None]
) -> Res_1246_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1245 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1246_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1245': channel_1245})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1246_pre(default=result)

class Respost_adapter_HAMRONIZATION_FARGENE_1246_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1246_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_FARGENE_1246_post(
    default: List[Dataclass_1246_post]
) -> Respost_adapter_HAMRONIZATION_FARGENE_1246_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_FARGENE_1246_post, default)


@task(cache=True)
def HAMRONIZATION_FARGENE_1246(
    default: Dataclass_1246_pre
) -> Dataclass_1246_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1245)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/fargene/main.nf", "alias": "HAMRONIZATION_FARGENE", "name": "HAMRONIZATION_FARGENE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_FARGENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"ConstantExpression":"0.1"},{"ConstantExpression":"0.1"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1246_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1247(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1247(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1244: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1247:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1244 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1244), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1247(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1250(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1250(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1247: typing.Union[str, None],
    channel_1235: typing.Union[str, None]
) -> ResMerge_ch_versions_1250:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1247 or channel_1235
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1250(
        res=res
    )


@dataclass
class Dataclass_1254_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1254_pre(NamedTuple):
    default: typing.List[Dataclass_1254_pre]

@task(cache=True)
def pre_adapter_RGI_MAIN_1254_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1253: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1254_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1253 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1254_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1254_pre(default=result)

class Respost_adapter_RGI_MAIN_1254_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    tmp: typing.Union[str, None]
    tool_version: typing.Union[str, None]
    db_version: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1254_post:
    json: str
    tsv: str
    tmp: str
    tool_version: str
    db_version: str
    versions: str

@task(cache=True)
def post_adapter_RGI_MAIN_1254_post(
    default: List[Dataclass_1254_post]
) -> Respost_adapter_RGI_MAIN_1254_post:
    return get_mapper_outputs(Respost_adapter_RGI_MAIN_1254_post, default)


@task(cache=True)
def RGI_MAIN_1254(
    default: Dataclass_1254_pre
) -> Dataclass_1254_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/rgi/main/main.nf", "alias": "RGI_MAIN", "name": "RGI_MAIN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RGI_MAIN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tmp\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tool_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"db_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1254_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        tmp=out_channels.get(f"tmp", ""),
        tool_version=out_channels.get(f"tool_version", ""),
        db_version=out_channels.get(f"db_version", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1255(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1255(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1253: typing.Union[bool, None],
    channel_1250: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1255:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1253 == True) and (channel_1250 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1250), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1255(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1256_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    tsv: str
    tool_version: str
    db_version: str


class Res_1256_pre(NamedTuple):
    default: typing.List[Dataclass_1256_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_RGI_1256_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1253: typing.Union[bool, None],
    tsv: typing.Union[str, None],
    tool_version: typing.Union[str, None],
    db_version: typing.Union[str, None]
) -> Res_1256_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1253 == True) and (tsv is not None) and (tool_version is not None) and (db_version is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1256_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'tsv': tsv, 'tool_version': tool_version, 'db_version': db_version})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1256_pre(default=result)

class Respost_adapter_HAMRONIZATION_RGI_1256_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1256_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_RGI_1256_post(
    default: List[Dataclass_1256_post]
) -> Respost_adapter_HAMRONIZATION_RGI_1256_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_RGI_1256_post, default)


@task(cache=True)
def HAMRONIZATION_RGI_1256(
    default: Dataclass_1256_pre
) -> Dataclass_1256_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.tsv),json.loads(default.tool_version),json.loads(default.db_version)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/rgi/main.nf", "alias": "HAMRONIZATION_RGI", "name": "HAMRONIZATION_RGI"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_RGI","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_RGI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_RGI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_RGI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1256_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1257(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1257(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1253: typing.Union[bool, None],
    channel_1255: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1257:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1253 == True) and (channel_1255 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1255), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1257(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1260(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1260(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1257: typing.Union[str, None],
    channel_1250: typing.Union[str, None]
) -> ResMerge_ch_versions_1260:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1257 or channel_1250
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1260(
        res=res
    )


class Res___1217(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___1217(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Res___1217:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res___1217(
        res=out_channels.get("res", "")
    )


class Resmap_1270(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1270(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    channel_1217: typing.Union[str, None]
) -> Resmap_1270:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (channel_1217 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1217)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"anno"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"model"},"operation":"=","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_model"}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"anno"},{"VariableExpression":"model"}]}}],"scope":{"declaredVariables":["meta","anno","model"],"referencedClassVariables":["params"]},"labels":[]}},"parameters":["it"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1270(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_deeparg_1261(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1261(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_deeparg_1261:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_deeparg"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1261(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_deeparg____params_arg_deeparg_data__1262(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_deeparg____params_arg_deeparg_data__1262(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1261: typing.Union[str, None]
) -> Res_params_arg_skip_deeparg____params_arg_deeparg_data__1262:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1261 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1261)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_data"}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_deeparg____params_arg_deeparg_data__1262(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_deeparg____params_arg_deeparg_data__1263(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_deeparg____params_arg_deeparg_data__1263(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1262: typing.Union[str, None]
) -> Res_params_arg_skip_deeparg____params_arg_deeparg_data__1263:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1262 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1262)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_deeparg____params_arg_deeparg_data__1263(
        res=out_channels.get("res", "")
    )


class Resconditional__params_arg_skip_deeparg____params_arg_deeparg_data__1264(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_arg_skip_deeparg____params_arg_deeparg_data__1264(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1263: typing.Union[str, None]
) -> Resconditional__params_arg_skip_deeparg____params_arg_deeparg_data__1264:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1263 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1263)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_arg_skip_deeparg____params_arg_deeparg_data__1264(condition=res)


class ResChannel_fromPath_params_arg_deeparg_data__1265(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_arg_deeparg_data__1265(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1264: typing.Union[bool, None]
) -> ResChannel_fromPath_params_arg_deeparg_data__1265:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1264 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_data"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_arg_deeparg_data__1265(
        res=out_channels.get("res", "")
    )


class Resfirst_1266(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1266(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1264: typing.Union[bool, None],
    channel_1265: typing.Union[str, None]
) -> Resfirst_1266:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1264 == True) and (channel_1265 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1265)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1266(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1271_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1270: str
    channel_1266: str


class Res_1271_pre(NamedTuple):
    default: typing.List[Dataclass_1271_pre]

@task(cache=True)
def pre_adapter_DEEPARG_PREDICT_1271_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    channel_1270: typing.Union[str, None],
    channel_1266: typing.Union[str, None]
) -> Res_1271_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (channel_1270 is not None) and (channel_1266 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1271_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1270': channel_1270, 'channel_1266': channel_1266})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1271_pre(default=result)

class Respost_adapter_DEEPARG_PREDICT_1271_post(NamedTuple):
    daa: typing.Union[str, None]
    daa_tsv: typing.Union[str, None]
    arg: typing.Union[str, None]
    potential_arg: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1271_post:
    daa: str
    daa_tsv: str
    arg: str
    potential_arg: str
    versions: str

@task(cache=True)
def post_adapter_DEEPARG_PREDICT_1271_post(
    default: List[Dataclass_1271_post]
) -> Respost_adapter_DEEPARG_PREDICT_1271_post:
    return get_mapper_outputs(Respost_adapter_DEEPARG_PREDICT_1271_post, default)


@task(cache=True)
def DEEPARG_PREDICT_1271(
    default: Dataclass_1271_pre
) -> Dataclass_1271_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1270),json.loads(default.channel_1266)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/deeparg/predict/main.nf", "alias": "DEEPARG_PREDICT", "name": "DEEPARG_PREDICT"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DEEPARG_PREDICT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"daa\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"daa_tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"arg\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"potential_arg\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1271_post(
        daa=out_channels.get(f"daa", ""),
        daa_tsv=out_channels.get(f"daa_tsv", ""),
        arg=out_channels.get(f"arg", ""),
        potential_arg=out_channels.get(f"potential_arg", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1272(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1272(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    channel_1260: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1272:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (channel_1260 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1260), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1272(
        res=out_channels.get("res", "")
    )


class Resmix_1273(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1273(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    arg: typing.Union[str, None],
    potential_arg: typing.Union[str, None]
) -> Resmix_1273:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (arg is not None) and (potential_arg is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(arg), json.loads(potential_arg)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1273(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1274_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1273: str


class Res_1274_pre(NamedTuple):
    default: typing.List[Dataclass_1274_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_DEEPARG_1274_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    channel_1273: typing.Union[str, None]
) -> Res_1274_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (channel_1273 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1274_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1273': channel_1273})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1274_pre(default=result)

class Respost_adapter_HAMRONIZATION_DEEPARG_1274_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1274_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_DEEPARG_1274_post(
    default: List[Dataclass_1274_post]
) -> Respost_adapter_HAMRONIZATION_DEEPARG_1274_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_DEEPARG_1274_post, default)


@task(cache=True)
def HAMRONIZATION_DEEPARG_1274(
    default: Dataclass_1274_pre
) -> Dataclass_1274_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1273)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/deeparg/main.nf", "alias": "HAMRONIZATION_DEEPARG", "name": "HAMRONIZATION_DEEPARG"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_DEEPARG","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"ConstantExpression":"1.0.2"},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_data_version"}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_DEEPARG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_DEEPARG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_DEEPARG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1274_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1275(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1275(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    channel_1272: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1275:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (channel_1272 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1272), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1275(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1278(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1278(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1275: typing.Union[str, None],
    channel_1260: typing.Union[str, None]
) -> ResMerge_ch_versions_1278:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1275 or channel_1260
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1278(
        res=res
    )


@dataclass
class Dataclass_1282_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1282_pre(NamedTuple):
    default: typing.List[Dataclass_1282_pre]

@task(cache=True)
def pre_adapter_ABRICATE_RUN_1282_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1281: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1282_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1281 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1282_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1282_pre(default=result)

class Respost_adapter_ABRICATE_RUN_1282_post(NamedTuple):
    report: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1282_post:
    report: str
    versions: str

@task(cache=True)
def post_adapter_ABRICATE_RUN_1282_post(
    default: List[Dataclass_1282_post]
) -> Respost_adapter_ABRICATE_RUN_1282_post:
    return get_mapper_outputs(Respost_adapter_ABRICATE_RUN_1282_post, default)


@task(cache=True)
def ABRICATE_RUN_1282(
    default: Dataclass_1282_pre
) -> Dataclass_1282_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/abricate/run/main.nf", "alias": "ABRICATE_RUN", "name": "ABRICATE_RUN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"ABRICATE_RUN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ABRICATE_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ABRICATE_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1282_post(
        report=out_channels.get(f"report", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1283(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1283(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1281: typing.Union[bool, None],
    channel_1278: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1283:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1281 == True) and (channel_1278 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1278), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1283(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1284_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    report: str


class Res_1284_pre(NamedTuple):
    default: typing.List[Dataclass_1284_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_ABRICATE_1284_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1281: typing.Union[bool, None],
    report: typing.Union[str, None]
) -> Res_1284_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1281 == True) and (report is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1284_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'report': report})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1284_pre(default=result)

class Respost_adapter_HAMRONIZATION_ABRICATE_1284_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1284_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_ABRICATE_1284_post(
    default: List[Dataclass_1284_post]
) -> Respost_adapter_HAMRONIZATION_ABRICATE_1284_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_ABRICATE_1284_post, default)


@task(cache=True)
def HAMRONIZATION_ABRICATE_1284(
    default: Dataclass_1284_pre
) -> Dataclass_1284_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.report)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/abricate/main.nf", "alias": "HAMRONIZATION_ABRICATE", "name": "HAMRONIZATION_ABRICATE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_ABRICATE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"ConstantExpression":"1.0.1"},{"ConstantExpression":"2021-Mar-27"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_ABRICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_ABRICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_ABRICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1284_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1285(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1285(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1281: typing.Union[bool, None],
    channel_1283: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1285:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1281 == True) and (channel_1283 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1283), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1285(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1288(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1288(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1285: typing.Union[str, None],
    channel_1278: typing.Union[str, None]
) -> ResMerge_ch_versions_1288:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1285 or channel_1278
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1288(
        res=res
    )


class ResChannel_empty___1219(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1219(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> ResChannel_empty___1219:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1219(
        res=out_channels.get("res", "")
    )


class Resmix_1233(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1233(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1228: typing.Union[bool, None],
    channel_1219: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1233:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1228 == True) and (channel_1219 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1219), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1233(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1234(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1234(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1233: typing.Union[str, None],
    channel_1219: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1234:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1233 or channel_1219
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1234(
        res=res
    )


class Resmix_1248(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1248(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1238: typing.Union[bool, None],
    channel_1234: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1248:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1238 == True) and (channel_1234 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1234), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1248(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1249(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1249(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1248: typing.Union[str, None],
    channel_1234: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1249:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1248 or channel_1234
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1249(
        res=res
    )


class Resmix_1258(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1258(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1253: typing.Union[bool, None],
    channel_1249: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1258:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1253 == True) and (channel_1249 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1249), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1258(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1259(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1259(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1258: typing.Union[str, None],
    channel_1249: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1259:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1258 or channel_1249
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1259(
        res=res
    )


class Resmix_1276(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1276(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1269: typing.Union[bool, None],
    channel_1259: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1276:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1269 == True) and (channel_1259 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1259), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1276(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1277(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1277(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1276: typing.Union[str, None],
    channel_1259: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1277:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1276 or channel_1259
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1277(
        res=res
    )


class Resmix_1286(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1286(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1281: typing.Union[bool, None],
    channel_1277: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1286:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (condition_1281 == True) and (channel_1277 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1277), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1286(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1287(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1287(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1286: typing.Union[str, None],
    channel_1277: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1287:
    cond = ((condition_1214 == True) and (condition_1216 == True))

    if cond:
        res = channel_1286 or channel_1277
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1287(
        res=res
    )


class Resmap_1289(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1289(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1287: typing.Union[str, None]
) -> Resmap_1289:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1287 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1287)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1289(
        res=out_channels.get("res", "")
    )


class Rescollect_1290(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_1290(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1289: typing.Union[str, None]
) -> Rescollect_1290:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1289 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1289)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescollect_1290(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1291_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1290: str


class Res_1291_pre(NamedTuple):
    default: typing.List[Dataclass_1291_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_SUMMARIZE_1291_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1290: typing.Union[str, None]
) -> Res_1291_pre:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1290 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1291_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1290': channel_1290})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1291_pre(default=result)

class Respost_adapter_HAMRONIZATION_SUMMARIZE_1291_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    html: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1291_post:
    json: str
    tsv: str
    html: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_SUMMARIZE_1291_post(
    default: List[Dataclass_1291_post]
) -> Respost_adapter_HAMRONIZATION_SUMMARIZE_1291_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_SUMMARIZE_1291_post, default)


@task(cache=True)
def HAMRONIZATION_SUMMARIZE_1291(
    default: Dataclass_1291_pre
) -> Dataclass_1291_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1290)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/summarize/main.nf", "alias": "HAMRONIZATION_SUMMARIZE", "name": "HAMRONIZATION_SUMMARIZE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_SUMMARIZE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_hamronization_summarizeformat"}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1291_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        html=out_channels.get(f"html", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1292(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1292(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1288: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1292:
    cond = ((condition_1214 == True) and (condition_1216 == True) and (channel_1288 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1288), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1292(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_abricate_1355(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_abricate_1355(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_abricate_1355:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_abricate"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_abricate_1355(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_abricate_1356(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_abricate_1356(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1355: typing.Union[str, None]
) -> Resparams_arg_skip_abricate_1356:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1355 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1355)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_abricate_1356(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_abricate_1357(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_abricate_1357(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1356: typing.Union[str, None]
) -> Resconditional_params_arg_skip_abricate_1357:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1356 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1356)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_abricate_1357(condition=res)


class Resparams_arg_skip_deeparg_1343(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1343(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_deeparg_1343:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_deeparg"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1343(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_deeparg_1344(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1344(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1343: typing.Union[str, None]
) -> Resparams_arg_skip_deeparg_1344:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1343 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1343)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1344(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_deeparg_1345(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_deeparg_1345(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1344: typing.Union[str, None]
) -> Resconditional_params_arg_skip_deeparg_1345:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1344 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1344)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_deeparg_1345(condition=res)


class Resparams_arg_skip_rgi_1327(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_rgi_1327(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_rgi_1327:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_rgi"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_rgi_1327(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_rgi_1328(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_rgi_1328(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1327: typing.Union[str, None]
) -> Resparams_arg_skip_rgi_1328:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1327 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1327)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_rgi_1328(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_rgi_1329(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_rgi_1329(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1328: typing.Union[str, None]
) -> Resconditional_params_arg_skip_rgi_1329:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1328 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1328)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_rgi_1329(condition=res)


class Resparams_arg_skip_fargene_1312(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_fargene_1312(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_fargene_1312:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_fargene"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_fargene_1312(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_fargene_1313(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_fargene_1313(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1312: typing.Union[str, None]
) -> Resparams_arg_skip_fargene_1313:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1312 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1312)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_fargene_1313(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_fargene_1314(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_fargene_1314(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1313: typing.Union[str, None]
) -> Resconditional_params_arg_skip_fargene_1314:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1313 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1313)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_fargene_1314(condition=res)


class Resparams_arg_skip_amrfinderplus_1302(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_amrfinderplus_1302(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_amrfinderplus_1302:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_amrfinderplus"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_amrfinderplus_1302(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_amrfinderplus_1303(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_amrfinderplus_1303(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1302: typing.Union[str, None]
) -> Resparams_arg_skip_amrfinderplus_1303:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1302 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1302)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_amrfinderplus_1303(
        res=out_channels.get("res", "")
    )


class Resconditional_params_arg_skip_amrfinderplus_1304(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_arg_skip_amrfinderplus_1304(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1303: typing.Union[str, None]
) -> Resconditional_params_arg_skip_amrfinderplus_1304:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1303 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1303)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_arg_skip_amrfinderplus_1304(condition=res)


class ResChannel_empty___1294(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1294(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> ResChannel_empty___1294:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1294(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_amrfinderplus_1296(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_amrfinderplus_1296(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_amrfinderplus_1296:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_amrfinderplus"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_amrfinderplus_1296(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1297(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1297(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1296: typing.Union[str, None]
) -> Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1297:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1296 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1296)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_amrfinderplus_db"}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1297(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1298(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1298(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1297: typing.Union[str, None]
) -> Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1298:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1297 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1297)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1298(
        res=out_channels.get("res", "")
    )


class Resconditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1299(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1299(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1298: typing.Union[str, None]
) -> Resconditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1299:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1298 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1298)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_arg_skip_amrfinderplus____params_arg_amrfinderplus_db__1299(condition=res)


class ResChannel_fromPath_params_arg_amrfinderplus_db__1300(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_arg_amrfinderplus_db__1300(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1299: typing.Union[bool, None]
) -> ResChannel_fromPath_params_arg_amrfinderplus_db__1300:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_amrfinderplus_db"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_arg_amrfinderplus_db__1300(
        res=out_channels.get("res", "")
    )


class Resfirst_1301(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1301(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1299: typing.Union[bool, None],
    channel_1300: typing.Union[str, None]
) -> Resfirst_1301:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1299 == True) and (channel_1300 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1300)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1301(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1305_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str
    channel_1301: str


class Res_1305_pre(NamedTuple):
    default: typing.List[Dataclass_1305_pre]

@task(cache=True)
def pre_adapter_AMRFINDERPLUS_RUN_1305_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1304: typing.Union[bool, None],
    channel_1101: typing.Union[str, None],
    channel_1301: typing.Union[str, None]
) -> Res_1305_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1304 == True) and (channel_1101 is not None) and (channel_1301 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1305_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101, 'channel_1301': channel_1301})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1305_pre(default=result)

class Respost_adapter_AMRFINDERPLUS_RUN_1305_post(NamedTuple):
    report: typing.Union[str, None]
    mutation_report: typing.Union[str, None]
    versions: typing.Union[str, None]
    tool_version: typing.Union[str, None]
    db_version: typing.Union[str, None]

@dataclass
class Dataclass_1305_post:
    report: str
    mutation_report: str
    versions: str
    tool_version: str
    db_version: str

@task(cache=True)
def post_adapter_AMRFINDERPLUS_RUN_1305_post(
    default: List[Dataclass_1305_post]
) -> Respost_adapter_AMRFINDERPLUS_RUN_1305_post:
    return get_mapper_outputs(Respost_adapter_AMRFINDERPLUS_RUN_1305_post, default)


@task(cache=True)
def AMRFINDERPLUS_RUN_1305(
    default: Dataclass_1305_pre
) -> Dataclass_1305_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101),json.loads(default.channel_1301)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/amrfinderplus/run/main.nf", "alias": "AMRFINDERPLUS_RUN", "name": "AMRFINDERPLUS_RUN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"AMRFINDERPLUS_RUN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mutation_report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tool_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"db_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"AMRFINDERPLUS_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1305_post(
        report=out_channels.get(f"report", ""),
        mutation_report=out_channels.get(f"mutation_report", ""),
        versions=out_channels.get(f"versions", ""),
        tool_version=out_channels.get(f"tool_version", ""),
        db_version=out_channels.get(f"db_version", "")
    )


class Resmix_1306(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1306(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1304: typing.Union[bool, None],
    channel_1294: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1306:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1304 == True) and (channel_1294 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1294), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1306(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1307_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    report: str
    tool_version: str
    db_version: str


class Res_1307_pre(NamedTuple):
    default: typing.List[Dataclass_1307_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_AMRFINDERPLUS_1307_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1304: typing.Union[bool, None],
    report: typing.Union[str, None],
    tool_version: typing.Union[str, None],
    db_version: typing.Union[str, None]
) -> Res_1307_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1304 == True) and (report is not None) and (tool_version is not None) and (db_version is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1307_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'report': report, 'tool_version': tool_version, 'db_version': db_version})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1307_pre(default=result)

class Respost_adapter_HAMRONIZATION_AMRFINDERPLUS_1307_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1307_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_AMRFINDERPLUS_1307_post(
    default: List[Dataclass_1307_post]
) -> Respost_adapter_HAMRONIZATION_AMRFINDERPLUS_1307_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_AMRFINDERPLUS_1307_post, default)


@task(cache=True)
def HAMRONIZATION_AMRFINDERPLUS_1307(
    default: Dataclass_1307_pre
) -> Dataclass_1307_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.report),json.loads(default.tool_version),json.loads(default.db_version)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/amrfinderplus/main.nf", "alias": "HAMRONIZATION_AMRFINDERPLUS", "name": "HAMRONIZATION_AMRFINDERPLUS"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_AMRFINDERPLUS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_AMRFINDERPLUS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_AMRFINDERPLUS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_AMRFINDERPLUS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1307_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1308(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1308(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1304: typing.Union[bool, None],
    channel_1306: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1308:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1304 == True) and (channel_1306 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1306), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1308(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1311(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1311(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1308: typing.Union[str, None],
    channel_1294: typing.Union[str, None]
) -> ResMerge_ch_versions_1311:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1308 or channel_1294
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1311(
        res=res
    )


class ResChannel_fromList_params_arg_fargene_hmmmodel_tokenize_____1315(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromList_params_arg_fargene_hmmmodel_tokenize_____1315(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None]
) -> ResChannel_fromList_params_arg_fargene_hmmmodel_tokenize_____1315:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromList","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_fargene_hmmmodel"}},"method":"tokenize","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":","}]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromList_params_arg_fargene_hmmmodel_tokenize_____1315(
        res=out_channels.get("res", "")
    )


class Rescombine_1316(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_1316(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1101: typing.Union[str, None],
    channel_1315: typing.Union[str, None]
) -> Rescombine_1316:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1101 is not None) and (channel_1315 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1101), json.loads(channel_1315)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescombine_1316(
        res=out_channels.get("res", "")
    )


class Resmap_1317(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1317(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1316: typing.Union[str, None]
) -> Resmap_1317:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1316 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1316)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"meta"},"method":"clone","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"[","rightExpression":{"ConstantExpression":"hmm_class"}}},"operation":"=","rightExpression":{"VariableExpression":"hmm_class"}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta_new"},{"VariableExpression":"contigs"},{"VariableExpression":"hmm_class"}]}}],"scope":{"declaredVariables":["meta_new"],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","contigs","hmm_class"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1317(
        res=out_channels.get("res", "")
    )


class ResmultiMap_1318(NamedTuple):
    contigs: typing.Union[str, None]
    hmmclass: typing.Union[str, None]

@task(cache=True)
def multiMap_1318(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1317: typing.Union[str, None]
) -> ResmultiMap_1318:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1317 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1317)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"multiMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}]},"labels":["contigs"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":2}}},"labels":["hmmclass"]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"contigs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"contigs\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"hmmclass\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"hmmclass\\"}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'contigs': None, 'hmmclass': None}

    return ResmultiMap_1318(
        contigs=out_channels.get("contigs", ""),
        hmmclass=out_channels.get("hmmclass", "")
    )


@dataclass
class Dataclass_1319_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    contigs: str
    hmmclass: str


class Res_1319_pre(NamedTuple):
    default: typing.List[Dataclass_1319_pre]

@task(cache=True)
def pre_adapter_FARGENE_1319_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    contigs: typing.Union[str, None],
    hmmclass: typing.Union[str, None]
) -> Res_1319_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (contigs is not None) and (hmmclass is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1319_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'contigs': contigs, 'hmmclass': hmmclass})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1319_pre(default=result)

class Respost_adapter_FARGENE_1319_post(NamedTuple):
    log: typing.Union[str, None]
    txt: typing.Union[str, None]
    hmm: typing.Union[str, None]
    orfs: typing.Union[str, None]
    orfs_amino: typing.Union[str, None]
    contigs: typing.Union[str, None]
    contigs_pept: typing.Union[str, None]
    filtered: typing.Union[str, None]
    filtered_pept: typing.Union[str, None]
    fragments: typing.Union[str, None]
    trimmed: typing.Union[str, None]
    spades: typing.Union[str, None]
    metagenome: typing.Union[str, None]
    tmp: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1319_post:
    log: str
    txt: str
    hmm: str
    orfs: str
    orfs_amino: str
    contigs: str
    contigs_pept: str
    filtered: str
    filtered_pept: str
    fragments: str
    trimmed: str
    spades: str
    metagenome: str
    tmp: str
    versions: str

@task(cache=True)
def post_adapter_FARGENE_1319_post(
    default: List[Dataclass_1319_post]
) -> Respost_adapter_FARGENE_1319_post:
    return get_mapper_outputs(Respost_adapter_FARGENE_1319_post, default)


@task(cache=True)
def FARGENE_1319(
    default: Dataclass_1319_pre
) -> Dataclass_1319_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.contigs),json.loads(default.hmmclass)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/fargene/main.nf", "alias": "FARGENE", "name": "FARGENE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FARGENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"hmm\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"orfs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"orfs_amino\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"contigs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"contigs_pept\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"filtered\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"filtered_pept\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fragments\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"trimmed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"spades\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"metagenome\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":12}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tmp\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":13}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":14}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1319_post(
        log=out_channels.get(f"log", ""),
        txt=out_channels.get(f"txt", ""),
        hmm=out_channels.get(f"hmm", ""),
        orfs=out_channels.get(f"orfs", ""),
        orfs_amino=out_channels.get(f"orfs_amino", ""),
        contigs=out_channels.get(f"contigs", ""),
        contigs_pept=out_channels.get(f"contigs_pept", ""),
        filtered=out_channels.get(f"filtered", ""),
        filtered_pept=out_channels.get(f"filtered_pept", ""),
        fragments=out_channels.get(f"fragments", ""),
        trimmed=out_channels.get(f"trimmed", ""),
        spades=out_channels.get(f"spades", ""),
        metagenome=out_channels.get(f"metagenome", ""),
        tmp=out_channels.get(f"tmp", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1320(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1320(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1311: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1320:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1311 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1311), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1320(
        res=out_channels.get("res", "")
    )


class Restranspose_1321(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def transpose_1321(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    hmm: typing.Union[str, None]
) -> Restranspose_1321:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (hmm is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(hmm)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"transpose","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Restranspose_1321(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1322_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1321: str


class Res_1322_pre(NamedTuple):
    default: typing.List[Dataclass_1322_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_FARGENE_1322_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1321: typing.Union[str, None]
) -> Res_1322_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1321 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1322_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1321': channel_1321})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1322_pre(default=result)

class Respost_adapter_HAMRONIZATION_FARGENE_1322_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1322_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_FARGENE_1322_post(
    default: List[Dataclass_1322_post]
) -> Respost_adapter_HAMRONIZATION_FARGENE_1322_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_FARGENE_1322_post, default)


@task(cache=True)
def HAMRONIZATION_FARGENE_1322(
    default: Dataclass_1322_pre
) -> Dataclass_1322_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1321)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/fargene/main.nf", "alias": "HAMRONIZATION_FARGENE", "name": "HAMRONIZATION_FARGENE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_FARGENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"ConstantExpression":"0.1"},{"ConstantExpression":"0.1"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_FARGENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1322_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1323(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1323(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1320: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1323:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1320 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1320), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1323(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1326(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1326(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1323: typing.Union[str, None],
    channel_1311: typing.Union[str, None]
) -> ResMerge_ch_versions_1326:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1323 or channel_1311
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1326(
        res=res
    )


@dataclass
class Dataclass_1330_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1330_pre(NamedTuple):
    default: typing.List[Dataclass_1330_pre]

@task(cache=True)
def pre_adapter_RGI_MAIN_1330_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1329: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1330_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1329 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1330_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1330_pre(default=result)

class Respost_adapter_RGI_MAIN_1330_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    tmp: typing.Union[str, None]
    tool_version: typing.Union[str, None]
    db_version: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1330_post:
    json: str
    tsv: str
    tmp: str
    tool_version: str
    db_version: str
    versions: str

@task(cache=True)
def post_adapter_RGI_MAIN_1330_post(
    default: List[Dataclass_1330_post]
) -> Respost_adapter_RGI_MAIN_1330_post:
    return get_mapper_outputs(Respost_adapter_RGI_MAIN_1330_post, default)


@task(cache=True)
def RGI_MAIN_1330(
    default: Dataclass_1330_pre
) -> Dataclass_1330_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/rgi/main/main.nf", "alias": "RGI_MAIN", "name": "RGI_MAIN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RGI_MAIN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tmp\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tool_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"db_version\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RGI_MAIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1330_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        tmp=out_channels.get(f"tmp", ""),
        tool_version=out_channels.get(f"tool_version", ""),
        db_version=out_channels.get(f"db_version", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1331(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1331(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1329: typing.Union[bool, None],
    channel_1326: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1331:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1329 == True) and (channel_1326 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1326), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1331(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1332_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    tsv: str
    tool_version: str
    db_version: str


class Res_1332_pre(NamedTuple):
    default: typing.List[Dataclass_1332_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_RGI_1332_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1329: typing.Union[bool, None],
    tsv: typing.Union[str, None],
    tool_version: typing.Union[str, None],
    db_version: typing.Union[str, None]
) -> Res_1332_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1329 == True) and (tsv is not None) and (tool_version is not None) and (db_version is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1332_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'tsv': tsv, 'tool_version': tool_version, 'db_version': db_version})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1332_pre(default=result)

class Respost_adapter_HAMRONIZATION_RGI_1332_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1332_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_RGI_1332_post(
    default: List[Dataclass_1332_post]
) -> Respost_adapter_HAMRONIZATION_RGI_1332_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_RGI_1332_post, default)


@task(cache=True)
def HAMRONIZATION_RGI_1332(
    default: Dataclass_1332_pre
) -> Dataclass_1332_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.tsv),json.loads(default.tool_version),json.loads(default.db_version)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/rgi/main.nf", "alias": "HAMRONIZATION_RGI", "name": "HAMRONIZATION_RGI"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_RGI","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_RGI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_RGI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_RGI\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1332_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1333(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1333(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1329: typing.Union[bool, None],
    channel_1331: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1333:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1329 == True) and (channel_1331 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1331), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1333(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1336(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1336(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1333: typing.Union[str, None],
    channel_1326: typing.Union[str, None]
) -> ResMerge_ch_versions_1336:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1333 or channel_1326
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1336(
        res=res
    )


class Resfilter_1293(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_1293(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1139: typing.Union[str, None]
) -> Resfilter_1293:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1139 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1139)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}},"ifBlock":{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}},"method":"warn","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"Annotation of following sample produced produced an empty FAA file. AMP screening tools requiring this file will not be executed: $meta.id","strings":[{"ConstantExpression":"Annotation of following sample produced produced an empty FAA file. AMP screening tools requiring this file will not be executed: "},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}]}}]}}}},"labels":[]}},"elseBlock":{"EmptyStatement":null},"labels":[]}},{"ReturnStatement":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":["meta","file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfilter_1293(
        res=out_channels.get("res", "")
    )


class Resmap_1346(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1346(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    channel_1293: typing.Union[str, None]
) -> Resmap_1346:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (channel_1293 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1293)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"anno"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"model"},"operation":"=","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_model"}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"anno"},{"VariableExpression":"model"}]}}],"scope":{"declaredVariables":["meta","anno","model"],"referencedClassVariables":["params"]},"labels":[]}},"parameters":["it"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1346(
        res=out_channels.get("res", "")
    )


class Resparams_arg_skip_deeparg_1337(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_arg_skip_deeparg_1337(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> Resparams_arg_skip_deeparg_1337:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_skip_deeparg"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_arg_skip_deeparg_1337(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_deeparg____params_arg_deeparg_data__1338(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_deeparg____params_arg_deeparg_data__1338(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1337: typing.Union[str, None]
) -> Res_params_arg_skip_deeparg____params_arg_deeparg_data__1338:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1337 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1337)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_data"}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_deeparg____params_arg_deeparg_data__1338(
        res=out_channels.get("res", "")
    )


class Res_params_arg_skip_deeparg____params_arg_deeparg_data__1339(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_arg_skip_deeparg____params_arg_deeparg_data__1339(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1338: typing.Union[str, None]
) -> Res_params_arg_skip_deeparg____params_arg_deeparg_data__1339:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1338 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1338)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Res_params_arg_skip_deeparg____params_arg_deeparg_data__1339(
        res=out_channels.get("res", "")
    )


class Resconditional__params_arg_skip_deeparg____params_arg_deeparg_data__1340(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_arg_skip_deeparg____params_arg_deeparg_data__1340(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1339: typing.Union[str, None]
) -> Resconditional__params_arg_skip_deeparg____params_arg_deeparg_data__1340:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1339 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1339)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_arg_skip_deeparg____params_arg_deeparg_data__1340(condition=res)


class ResChannel_fromPath_params_arg_deeparg_data__1341(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath_params_arg_deeparg_data__1341(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1340: typing.Union[bool, None]
) -> ResChannel_fromPath_params_arg_deeparg_data__1341:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1340 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_data"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath_params_arg_deeparg_data__1341(
        res=out_channels.get("res", "")
    )


class Resfirst_1342(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_1342(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1340: typing.Union[bool, None],
    channel_1341: typing.Union[str, None]
) -> Resfirst_1342:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1340 == True) and (channel_1341 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1341)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfirst_1342(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1347_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1346: str
    channel_1342: str


class Res_1347_pre(NamedTuple):
    default: typing.List[Dataclass_1347_pre]

@task(cache=True)
def pre_adapter_DEEPARG_PREDICT_1347_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    channel_1346: typing.Union[str, None],
    channel_1342: typing.Union[str, None]
) -> Res_1347_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (channel_1346 is not None) and (channel_1342 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1347_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1346': channel_1346, 'channel_1342': channel_1342})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1347_pre(default=result)

class Respost_adapter_DEEPARG_PREDICT_1347_post(NamedTuple):
    daa: typing.Union[str, None]
    daa_tsv: typing.Union[str, None]
    arg: typing.Union[str, None]
    potential_arg: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1347_post:
    daa: str
    daa_tsv: str
    arg: str
    potential_arg: str
    versions: str

@task(cache=True)
def post_adapter_DEEPARG_PREDICT_1347_post(
    default: List[Dataclass_1347_post]
) -> Respost_adapter_DEEPARG_PREDICT_1347_post:
    return get_mapper_outputs(Respost_adapter_DEEPARG_PREDICT_1347_post, default)


@task(cache=True)
def DEEPARG_PREDICT_1347(
    default: Dataclass_1347_pre
) -> Dataclass_1347_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1346),json.loads(default.channel_1342)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/deeparg/predict/main.nf", "alias": "DEEPARG_PREDICT", "name": "DEEPARG_PREDICT"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DEEPARG_PREDICT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"daa\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"daa_tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"arg\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"potential_arg\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DEEPARG_PREDICT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1347_post(
        daa=out_channels.get(f"daa", ""),
        daa_tsv=out_channels.get(f"daa_tsv", ""),
        arg=out_channels.get(f"arg", ""),
        potential_arg=out_channels.get(f"potential_arg", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1348(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1348(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    channel_1336: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1348:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (channel_1336 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1336), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1348(
        res=out_channels.get("res", "")
    )


class Resmix_1349(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1349(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    arg: typing.Union[str, None],
    potential_arg: typing.Union[str, None]
) -> Resmix_1349:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (arg is not None) and (potential_arg is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(arg), json.loads(potential_arg)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1349(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1350_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1349: str


class Res_1350_pre(NamedTuple):
    default: typing.List[Dataclass_1350_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_DEEPARG_1350_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    channel_1349: typing.Union[str, None]
) -> Res_1350_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (channel_1349 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1350_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1349': channel_1349})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1350_pre(default=result)

class Respost_adapter_HAMRONIZATION_DEEPARG_1350_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1350_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_DEEPARG_1350_post(
    default: List[Dataclass_1350_post]
) -> Respost_adapter_HAMRONIZATION_DEEPARG_1350_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_DEEPARG_1350_post, default)


@task(cache=True)
def HAMRONIZATION_DEEPARG_1350(
    default: Dataclass_1350_pre
) -> Dataclass_1350_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1349)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/deeparg/main.nf", "alias": "HAMRONIZATION_DEEPARG", "name": "HAMRONIZATION_DEEPARG"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_DEEPARG","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"ConstantExpression":"1.0.2"},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_deeparg_data_version"}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_DEEPARG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_DEEPARG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_DEEPARG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1350_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1351(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1351(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    channel_1348: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1351:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (channel_1348 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1348), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1351(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1354(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1354(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1351: typing.Union[str, None],
    channel_1336: typing.Union[str, None]
) -> ResMerge_ch_versions_1354:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1351 or channel_1336
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1354(
        res=res
    )


@dataclass
class Dataclass_1358_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1101: str


class Res_1358_pre(NamedTuple):
    default: typing.List[Dataclass_1358_pre]

@task(cache=True)
def pre_adapter_ABRICATE_RUN_1358_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1357: typing.Union[bool, None],
    channel_1101: typing.Union[str, None]
) -> Res_1358_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1357 == True) and (channel_1101 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1358_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1101': channel_1101})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1358_pre(default=result)

class Respost_adapter_ABRICATE_RUN_1358_post(NamedTuple):
    report: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1358_post:
    report: str
    versions: str

@task(cache=True)
def post_adapter_ABRICATE_RUN_1358_post(
    default: List[Dataclass_1358_post]
) -> Respost_adapter_ABRICATE_RUN_1358_post:
    return get_mapper_outputs(Respost_adapter_ABRICATE_RUN_1358_post, default)


@task(cache=True)
def ABRICATE_RUN_1358(
    default: Dataclass_1358_pre
) -> Dataclass_1358_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1101)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/abricate/run/main.nf", "alias": "ABRICATE_RUN", "name": "ABRICATE_RUN"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"ABRICATE_RUN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ABRICATE_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"ABRICATE_RUN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1358_post(
        report=out_channels.get(f"report", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1359(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1359(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1357: typing.Union[bool, None],
    channel_1354: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1359:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1357 == True) and (channel_1354 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1354), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1359(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1360_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    report: str


class Res_1360_pre(NamedTuple):
    default: typing.List[Dataclass_1360_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_ABRICATE_1360_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1357: typing.Union[bool, None],
    report: typing.Union[str, None]
) -> Res_1360_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1357 == True) and (report is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1360_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'report': report})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1360_pre(default=result)

class Respost_adapter_HAMRONIZATION_ABRICATE_1360_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1360_post:
    json: str
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_ABRICATE_1360_post(
    default: List[Dataclass_1360_post]
) -> Respost_adapter_HAMRONIZATION_ABRICATE_1360_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_ABRICATE_1360_post, default)


@task(cache=True)
def HAMRONIZATION_ABRICATE_1360(
    default: Dataclass_1360_pre
) -> Dataclass_1360_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.report)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/abricate/main.nf", "alias": "HAMRONIZATION_ABRICATE", "name": "HAMRONIZATION_ABRICATE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_ABRICATE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"json"},{"ConstantExpression":"1.0.1"},{"ConstantExpression":"2021-Mar-27"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_ABRICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_ABRICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_ABRICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1360_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1361(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1361(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1357: typing.Union[bool, None],
    channel_1359: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1361:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1357 == True) and (channel_1359 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1359), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1361(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1364(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1364(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1361: typing.Union[str, None],
    channel_1354: typing.Union[str, None]
) -> ResMerge_ch_versions_1364:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1361 or channel_1354
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1364(
        res=res
    )


class ResChannel_empty___1295(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1295(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None]
) -> ResChannel_empty___1295:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1295(
        res=out_channels.get("res", "")
    )


class Resmix_1309(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1309(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1304: typing.Union[bool, None],
    channel_1295: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1309:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1304 == True) and (channel_1295 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1295), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1309(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1310(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1310(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1309: typing.Union[str, None],
    channel_1295: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1310:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1309 or channel_1295
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1310(
        res=res
    )


class Resmix_1324(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1324(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1314: typing.Union[bool, None],
    channel_1310: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1324:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1314 == True) and (channel_1310 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1310), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1324(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1325(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1325(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1324: typing.Union[str, None],
    channel_1310: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1325:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1324 or channel_1310
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1325(
        res=res
    )


class Resmix_1334(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1334(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1329: typing.Union[bool, None],
    channel_1325: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1334:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1329 == True) and (channel_1325 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1325), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1334(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1335(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1335(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1334: typing.Union[str, None],
    channel_1325: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1335:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1334 or channel_1325
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1335(
        res=res
    )


class Resmix_1352(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1352(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1345: typing.Union[bool, None],
    channel_1335: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1352:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1345 == True) and (channel_1335 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1335), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1352(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1353(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1353(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1352: typing.Union[str, None],
    channel_1335: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1353:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1352 or channel_1335
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1353(
        res=res
    )


class Resmix_1362(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1362(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    condition_1357: typing.Union[bool, None],
    channel_1353: typing.Union[str, None],
    json: typing.Union[str, None]
) -> Resmix_1362:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (condition_1357 == True) and (channel_1353 is not None) and (json is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1353), json.loads(json)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1362(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_input_to_hamronization_summarize_1363(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_input_to_hamronization_summarize_1363(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1362: typing.Union[str, None],
    channel_1353: typing.Union[str, None]
) -> ResMerge_ch_input_to_hamronization_summarize_1363:
    cond = ((condition_1214 == True) and (condition_1216 == False))

    if cond:
        res = channel_1362 or channel_1353
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_input_to_hamronization_summarize_1363(
        res=res
    )


class Resmap_1365(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1365(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1363: typing.Union[str, None]
) -> Resmap_1365:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1363 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1363)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1365(
        res=out_channels.get("res", "")
    )


class Rescollect_1366(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_1366(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1365: typing.Union[str, None]
) -> Rescollect_1366:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1365 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1365)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescollect_1366(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1367_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1366: str


class Res_1367_pre(NamedTuple):
    default: typing.List[Dataclass_1367_pre]

@task(cache=True)
def pre_adapter_HAMRONIZATION_SUMMARIZE_1367_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1366: typing.Union[str, None]
) -> Res_1367_pre:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1366 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1367_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1366': channel_1366})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1367_pre(default=result)

class Respost_adapter_HAMRONIZATION_SUMMARIZE_1367_post(NamedTuple):
    json: typing.Union[str, None]
    tsv: typing.Union[str, None]
    html: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1367_post:
    json: str
    tsv: str
    html: str
    versions: str

@task(cache=True)
def post_adapter_HAMRONIZATION_SUMMARIZE_1367_post(
    default: List[Dataclass_1367_post]
) -> Respost_adapter_HAMRONIZATION_SUMMARIZE_1367_post:
    return get_mapper_outputs(Respost_adapter_HAMRONIZATION_SUMMARIZE_1367_post, default)


@task(cache=True)
def HAMRONIZATION_SUMMARIZE_1367(
    default: Dataclass_1367_pre
) -> Dataclass_1367_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1366)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hamronization/summarize/main.nf", "alias": "HAMRONIZATION_SUMMARIZE", "name": "HAMRONIZATION_SUMMARIZE"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HAMRONIZATION_SUMMARIZE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"arg_hamronization_summarizeformat"}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HAMRONIZATION_SUMMARIZE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1367_post(
        json=out_channels.get(f"json", ""),
        tsv=out_channels.get(f"tsv", ""),
        html=out_channels.get(f"html", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1368(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1368(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    condition_1216: typing.Union[bool, None],
    channel_1364: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1368:
    cond = ((condition_1214 == True) and (condition_1216 == False) and (channel_1364 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1364), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1368(
        res=out_channels.get("res", "")
    )


class ResMerge_ARG_1369(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ARG_1369(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    channel_1292: typing.Union[str, None],
    channel_1368: typing.Union[str, None]
) -> ResMerge_ARG_1369:
    cond = ((condition_1214 == True))

    if cond:
        res = channel_1292 or channel_1368
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ARG_1369(
        res=res
    )


class Resmix_1370(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1370(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1214: typing.Union[bool, None],
    channel_1212: typing.Union[str, None],
    channel_1369: typing.Union[str, None]
) -> Resmix_1370:
    cond = ((condition_1214 == True) and (channel_1212 is not None) and (channel_1369 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1212), json.loads(channel_1369)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1370(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1371(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1371(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1370: typing.Union[str, None],
    channel_1212: typing.Union[str, None]
) -> ResMerge_ch_versions_1371:
    cond = True

    if cond:
        res = channel_1370 or channel_1212
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1371(
        res=res
    )


class ResChannel_empty___1377(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1377(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None]
) -> ResChannel_empty___1377:
    cond = ((condition_1373 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1377(
        res=out_channels.get("res", "")
    )


class Resmix_1394(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1394(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1377: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1394:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1377 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1377), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1394(
        res=out_channels.get("res", "")
    )


class Resmix_1397(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1397(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1394: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1397:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1394 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1394), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1397(
        res=out_channels.get("res", "")
    )


class Resmix_1400(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1400(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1397: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1400:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1397 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1397), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1400(
        res=out_channels.get("res", "")
    )


class Resmix_1405(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1405(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    condition_1384: typing.Union[bool, None],
    channel_1400: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1405:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (condition_1384 == False) and (channel_1400 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1400), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1405(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1408(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1408(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1377: typing.Union[str, None],
    channel_1405: typing.Union[str, None]
) -> ResMerge_ch_versions_1408:
    cond = ((condition_1373 == True) and (condition_1381 == True))

    if cond:
        res = channel_1377 or channel_1405
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1408(
        res=res
    )


class Resmix_1418(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1418(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1381: typing.Union[bool, None],
    channel_1408: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1418:
    cond = ((condition_1373 == True) and (condition_1381 == True) and (channel_1408 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1408), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1418(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1423(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1423(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1418: typing.Union[str, None],
    channel_1377: typing.Union[str, None]
) -> ResMerge_ch_versions_1423:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1418 or channel_1377
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1423(
        res=res
    )


class Resmix_1433(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1433(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    condition_1429: typing.Union[bool, None],
    channel_1423: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1433:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (condition_1429 == False) and (channel_1423 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1423), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1433(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1435(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1435(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    channel_1423: typing.Union[str, None],
    channel_1433: typing.Union[str, None]
) -> ResMerge_ch_versions_1435:
    cond = ((condition_1373 == True) and (condition_1427 == True))

    if cond:
        res = channel_1423 or channel_1433
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1435(
        res=res
    )


class Resmix_1437(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1437(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1427: typing.Union[bool, None],
    channel_1435: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1437:
    cond = ((condition_1373 == True) and (condition_1427 == True) and (channel_1435 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1435), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1437(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1440(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1440(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1437: typing.Union[str, None],
    channel_1423: typing.Union[str, None]
) -> ResMerge_ch_versions_1440:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1437 or channel_1423
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1440(
        res=res
    )


class Resmix_1447(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1447(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1443: typing.Union[bool, None],
    channel_1440: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1447:
    cond = ((condition_1373 == True) and (condition_1443 == True) and (channel_1440 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1440), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1447(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1453(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1453(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1447: typing.Union[str, None],
    channel_1440: typing.Union[str, None]
) -> ResMerge_ch_versions_1453:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1447 or channel_1440
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1453(
        res=res
    )


class Resfilter_1375(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_1375(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1139: typing.Union[str, None]
) -> Resfilter_1375:
    cond = ((condition_1373 == True) and (channel_1139 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1139)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}},"ifBlock":{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}},"method":"warn","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"Annotation of following sample produced produced an empty FAA file. AMP screening tools requiring this file will not be executed: $meta.id","strings":[{"ConstantExpression":"Annotation of following sample produced produced an empty FAA file. AMP screening tools requiring this file will not be executed: "},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}]}}]}}}},"labels":[]}},"elseBlock":{"EmptyStatement":null},"labels":[]}},{"ReturnStatement":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"file"},"method":"isEmpty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":["meta","file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resfilter_1375(
        res=out_channels.get("res", "")
    )


class ResChannel_fromPath__checkIfExists_true___params_bgc_hmmsearch_mode_1459(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_bgc_hmmsearch_mode_1459(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    condition_1458: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_bgc_hmmsearch_mode_1459:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (condition_1458 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_hmmsearch_models"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_bgc_hmmsearch_mode_1459(
        res=out_channels.get("res", "")
    )


class Resmap_1461(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1461(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    channel_1459: typing.Union[str, None]
) -> Resmap_1461:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (channel_1459 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1459)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"=","rightExpression":{"MapExpression":[]}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}},"operation":"=","rightExpression":{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"file"},"property":"extension"}},{"ConstantExpression":"gz"}]}}}}},"trueExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"file"},"property":"name"}},"operation":"-","rightExpression":{"ConstantExpression":".hmm.gz"}}},"falseExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"file"},"property":"name"}},"operation":"-","rightExpression":{"ConstantExpression":".hmm"}}}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"file"}]}}],"scope":{"declaredVariables":["meta"],"referencedClassVariables":["compareEqual"]},"labels":[]}},"parameters":["file"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1461(
        res=out_channels.get("res", "")
    )


class Rescombine_1462(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_1462(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    channel_1375: typing.Union[str, None],
    channel_1461: typing.Union[str, None]
) -> Rescombine_1462:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (channel_1375 is not None) and (channel_1461 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1375), json.loads(channel_1461)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescombine_1462(
        res=out_channels.get("res", "")
    )


class Resmap_1463(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_1463(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    channel_1462: typing.Union[str, None]
) -> Resmap_1463:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (channel_1462 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1462)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"=","rightExpression":{"MapExpression":[]}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_faa"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_new"},"operation":"[","rightExpression":{"ConstantExpression":"hmm_id"}}},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_hmm"},"operation":"[","rightExpression":{"ConstantExpression":"id"}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta_new"},{"VariableExpression":"hmm"},{"VariableExpression":"faa"},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_hmmsearch_savealignments"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_hmmsearch_savetargets"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bgc_hmmsearch_savedomains"}}]}}],"scope":{"declaredVariables":["meta_new"],"referencedClassVariables":["params"]},"labels":[]}},"parameters":["meta_faa","faa","meta_hmm","hmm"]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmap_1463(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1464_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1463: str


class Res_1464_pre(NamedTuple):
    default: typing.List[Dataclass_1464_pre]

@task(cache=True)
def pre_adapter_BGC_HMMER_HMMSEARCH_1464_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    channel_1463: typing.Union[str, None]
) -> Res_1464_pre:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (channel_1463 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1464_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1463': channel_1463})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1464_pre(default=result)

class Respost_adapter_BGC_HMMER_HMMSEARCH_1464_post(NamedTuple):
    output: typing.Union[str, None]
    alignments: typing.Union[str, None]
    target_summary: typing.Union[str, None]
    domain_summary: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1464_post:
    output: str
    alignments: str
    target_summary: str
    domain_summary: str
    versions: str

@task(cache=True)
def post_adapter_BGC_HMMER_HMMSEARCH_1464_post(
    default: List[Dataclass_1464_post]
) -> Respost_adapter_BGC_HMMER_HMMSEARCH_1464_post:
    return get_mapper_outputs(Respost_adapter_BGC_HMMER_HMMSEARCH_1464_post, default)


@task(cache=True)
def BGC_HMMER_HMMSEARCH_1464(
    default: Dataclass_1464_pre
) -> Dataclass_1464_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1463)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/hmmer/hmmsearch/main.nf", "alias": "BGC_HMMER_HMMSEARCH", "name": "HMMER_HMMSEARCH"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BGC_HMMER_HMMSEARCH","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"output\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BGC_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"alignments\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BGC_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"target_summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BGC_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"domain_summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BGC_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BGC_HMMER_HMMSEARCH\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1464_post(
        output=out_channels.get(f"output", ""),
        alignments=out_channels.get(f"alignments", ""),
        target_summary=out_channels.get(f"target_summary", ""),
        domain_summary=out_channels.get(f"domain_summary", ""),
        versions=out_channels.get(f"versions", "")
    )


class Resmix_1465(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1465(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    condition_1456: typing.Union[bool, None],
    channel_1453: typing.Union[str, None],
    versions: typing.Union[str, None]
) -> Resmix_1465:
    cond = ((condition_1373 == True) and (condition_1456 == True) and (channel_1453 is not None) and (versions is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1453), json.loads(versions)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1465(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1466(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1466(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1465: typing.Union[str, None],
    channel_1453: typing.Union[str, None]
) -> ResMerge_ch_versions_1466:
    cond = ((condition_1373 == True))

    if cond:
        res = channel_1465 or channel_1453
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1466(
        res=res
    )


class Resmix_1470(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1470(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1373: typing.Union[bool, None],
    channel_1371: typing.Union[str, None],
    channel_1466: typing.Union[str, None]
) -> Resmix_1470:
    cond = ((condition_1373 == True) and (channel_1371 is not None) and (channel_1466 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1371), json.loads(channel_1466)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1470(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_versions_1471(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_1471(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1470: typing.Union[str, None],
    channel_1371: typing.Union[str, None]
) -> ResMerge_ch_versions_1471:
    cond = True

    if cond:
        res = channel_1470 or channel_1371
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_versions_1471(
        res=res
    )


class Resunique_1472(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def unique_1472(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1471: typing.Union[str, None]
) -> Resunique_1472:
    cond = ((channel_1471 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1471)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"unique","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resunique_1472(
        res=out_channels.get("res", "")
    )


class RescollectFile_1473(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_1473(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1472: typing.Union[str, None]
) -> RescollectFile_1473:
    cond = ((channel_1472 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1472)]

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"collated_versions.yml"}}}]}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RescollectFile_1473(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1474_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1473: str


class Res_1474_pre(NamedTuple):
    default: typing.List[Dataclass_1474_pre]

@task(cache=True)
def pre_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_1474_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1473: typing.Union[str, None]
) -> Res_1474_pre:
    cond = ((channel_1473 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1474_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1473': channel_1473})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1474_pre(default=result)

class Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_1474_post(NamedTuple):
    yml: typing.Union[str, None]
    mqc_yml: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1474_post:
    yml: str
    mqc_yml: str
    versions: str

@task(cache=True)
def post_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_1474_post(
    default: List[Dataclass_1474_post]
) -> Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_1474_post:
    return get_mapper_outputs(Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_1474_post, default)


@task(cache=True)
def CUSTOM_DUMPSOFTWAREVERSIONS_1474(
    default: Dataclass_1474_pre
) -> Dataclass_1474_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1473)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/custom/dumpsoftwareversions/main.nf", "alias": "CUSTOM_DUMPSOFTWAREVERSIONS", "name": "CUSTOM_DUMPSOFTWAREVERSIONS"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_DUMPSOFTWAREVERSIONS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mqc_yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1474_post(
        yml=out_channels.get(f"yml", ""),
        mqc_yml=out_channels.get(f"mqc_yml", ""),
        versions=out_channels.get(f"versions", "")
    )


class Rescollect_1476(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_1476(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    mqc_yml: typing.Union[str, None]
) -> Rescollect_1476:
    cond = ((mqc_yml is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(mqc_yml)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescollect_1476(
        res=out_channels.get("res", "")
    )


class Resmix_1477(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1477(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1475: typing.Union[str, None],
    channel_1476: typing.Union[str, None]
) -> Resmix_1477:
    cond = ((channel_1475 is not None) and (channel_1476 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1475), json.loads(channel_1476)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1477(
        res=out_channels.get("res", "")
    )


class Rescollect_1481(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_1481(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1480: typing.Union[bool, None]
) -> Rescollect_1481:
    cond = ((condition_1480 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescollect_1481(
        res=out_channels.get("res", "")
    )


class ResifEmpty_1482(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_1482(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1480: typing.Union[bool, None],
    channel_1481: typing.Union[str, None]
) -> ResifEmpty_1482:
    cond = ((condition_1480 == True) and (channel_1481 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1481)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResifEmpty_1482(
        res=out_channels.get("res", "")
    )


class Resmix_1483(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_1483(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1480: typing.Union[bool, None],
    channel_1477: typing.Union[str, None],
    channel_1482: typing.Union[str, None]
) -> Resmix_1483:
    cond = ((condition_1480 == True) and (channel_1477 is not None) and (channel_1482 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1477), json.loads(channel_1482)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resmix_1483(
        res=out_channels.get("res", "")
    )


class ResMerge_ch_multiqc_files_1484(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_multiqc_files_1484(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1483: typing.Union[str, None],
    channel_1477: typing.Union[str, None]
) -> ResMerge_ch_multiqc_files_1484:
    cond = True

    if cond:
        res = channel_1483 or channel_1477
    else:
        print("TASK SKIPPED")
        res = None

    return ResMerge_ch_multiqc_files_1484(
        res=res
    )


class Resview_1485(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def view_1485(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1484: typing.Union[str, None]
) -> Resview_1485:
    cond = ((channel_1484 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1484)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"view","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"GStringExpression":{"verbatimText":"<_^_> ch_multiqc_files: $it","strings":[{"ConstantExpression":"<_^_> ch_multiqc_files: "},{"ConstantExpression":""}],"values":[{"VariableExpression":"it"}]}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resview_1485(
        res=out_channels.get("res", "")
    )


class ResChannel_fromPath__checkIfExists_true____projectDir_assets_multiq_1080(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true____projectDir_assets_multiq_1080(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> ResChannel_fromPath__checkIfExists_true____projectDir_assets_multiq_1080:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"GStringExpression":{"verbatimText":"$projectDir/assets/multiqc_config.yml","strings":[{"ConstantExpression":""},{"ConstantExpression":"/assets/multiqc_config.yml"}],"values":[{"VariableExpression":"projectDir"}]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true____projectDir_assets_multiq_1080(
        res=out_channels.get("res", "")
    )


class Resview_1486(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def view_1486(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1080: typing.Union[str, None]
) -> Resview_1486:
    cond = ((channel_1080 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1080)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"view","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"GStringExpression":{"verbatimText":"<_^_> ch_multiqc_config: $it","strings":[{"ConstantExpression":"<_^_> ch_multiqc_config: "},{"ConstantExpression":""}],"values":[{"VariableExpression":"it"}]}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resview_1486(
        res=out_channels.get("res", "")
    )


class Resparams_multiqc_config_1081(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_multiqc_config_1081(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> Resparams_multiqc_config_1081:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_config"}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resparams_multiqc_config_1081(
        res=out_channels.get("res", "")
    )


class Resconditional_params_multiqc_config_1082(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_multiqc_config_1082(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1081: typing.Union[str, None]
) -> Resconditional_params_multiqc_config_1082:
    cond = ((channel_1081 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1081)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'condition': None}

    res = out_channels.get('condition')

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_multiqc_config_1082(condition=res)


class ResChannel_fromPath__checkIfExists_true___params_multiqc_config__1083(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_multiqc_config__1083(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1082: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_multiqc_config__1083:
    cond = ((condition_1082 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_config"}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_multiqc_config__1083(
        res=out_channels.get("res", "")
    )


class ResChannel_empty___1084(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___1084(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    condition_1082: typing.Union[bool, None]
) -> ResChannel_empty___1084:
    cond = ((condition_1082 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_empty___1084(
        res=out_channels.get("res", "")
    )


class Res_params_multiqc_config____Channel_fromPath__checkIfExists_true___1085(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_multiqc_config____Channel_fromPath__checkIfExists_true___1085(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1083: typing.Union[str, None],
    channel_1084: typing.Union[str, None]
) -> Res_params_multiqc_config____Channel_fromPath__checkIfExists_true___1085:
    cond = True

    if cond:
        res = channel_1083 or channel_1084
    else:
        print("TASK SKIPPED")
        res = None

    return Res_params_multiqc_config____Channel_fromPath__checkIfExists_true___1085(
        res=res
    )


class Resview_1487(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def view_1487(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1085: typing.Union[str, None]
) -> Resview_1487:
    cond = ((channel_1085 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1085)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"view","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"GStringExpression":{"verbatimText":"<_^_> ch_multiqc_custom_config: $it","strings":[{"ConstantExpression":"<_^_> ch_multiqc_custom_config: "},{"ConstantExpression":""}],"values":[{"VariableExpression":"it"}]}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resview_1487(
        res=out_channels.get("res", "")
    )


class ResChannel_fromPath__projectDir_docs_images_nf_core_funcscan_logo_f_1092(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__projectDir_docs_images_nf_core_funcscan_logo_f_1092(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir
) -> ResChannel_fromPath__projectDir_docs_images_nf_core_funcscan_logo_f_1092:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = []

        download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"GStringExpression":{"verbatimText":"$projectDir/docs/images/nf-core-funcscan_logo_flat_light.png","strings":[{"ConstantExpression":""},{"ConstantExpression":"/docs/images/nf-core-funcscan_logo_flat_light.png"}],"values":[{"VariableExpression":"projectDir"}]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()

        upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return ResChannel_fromPath__projectDir_docs_images_nf_core_funcscan_logo_f_1092(
        res=out_channels.get("res", "")
    )


class Resview_1488(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def view_1488(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1092: typing.Union[str, None]
) -> Resview_1488:
    cond = ((channel_1092 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1092)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"view","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"GStringExpression":{"verbatimText":"<_^_> ch_multiqc_logo: $it","strings":[{"ConstantExpression":"<_^_> ch_multiqc_logo: "},{"ConstantExpression":""}],"values":[{"VariableExpression":"it"}]}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Resview_1488(
        res=out_channels.get("res", "")
    )


class Rescollect_1489(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_1489(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1484: typing.Union[str, None]
) -> Rescollect_1489:
    cond = ((channel_1484 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1484)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return Rescollect_1489(
        res=out_channels.get("res", "")
    )


class RestoList_1490(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_1490(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1080: typing.Union[str, None]
) -> RestoList_1490:
    cond = ((channel_1080 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1080)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RestoList_1490(
        res=out_channels.get("res", "")
    )


class RestoList_1491(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_1491(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1085: typing.Union[str, None]
) -> RestoList_1491:
    cond = ((channel_1085 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1085)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RestoList_1491(
        res=out_channels.get("res", "")
    )


class RestoList_1492(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_1492(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1092: typing.Union[str, None]
) -> RestoList_1492:
    cond = ((channel_1092 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(channel_1092)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RestoList_1492(
        res=out_channels.get("res", "")
    )


@dataclass
class Dataclass_1493_pre:
    wf_input: LatchFile
    wf_outdir: LatchOutputDir
    channel_1489: str
    channel_1490: str
    channel_1491: str
    channel_1492: str


class Res_1493_pre(NamedTuple):
    default: typing.List[Dataclass_1493_pre]

@task(cache=True)
def pre_adapter_MULTIQC_1493_pre(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    channel_1489: typing.Union[str, None],
    channel_1490: typing.Union[str, None],
    channel_1491: typing.Union[str, None],
    channel_1492: typing.Union[str, None]
) -> Res_1493_pre:
    cond = ((channel_1489 is not None) and (channel_1490 is not None) and (channel_1491 is not None) and (channel_1492 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_1493_pre, {'wf_input': wf_input, 'wf_outdir': wf_outdir}, {'channel_1489': channel_1489, 'channel_1490': channel_1490, 'channel_1491': channel_1491, 'channel_1492': channel_1492})
    else:
        print("TASK SKIPPED")
        result = []

    return Res_1493_pre(default=result)

class Respost_adapter_MULTIQC_1493_post(NamedTuple):
    report: typing.Union[str, None]
    data: typing.Union[str, None]
    plots: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_1493_post:
    report: str
    data: str
    plots: str
    versions: str

@task(cache=True)
def post_adapter_MULTIQC_1493_post(
    default: List[Dataclass_1493_post]
) -> Respost_adapter_MULTIQC_1493_post:
    return get_mapper_outputs(Respost_adapter_MULTIQC_1493_post, default)


@task(cache=True)
def MULTIQC_1493(
    default: Dataclass_1493_pre
) -> Dataclass_1493_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        wf_input_p = Path(wf_input).resolve()
        check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
        wf_paths[wf_input] = Path("/root") / wf_input_p.name

    wf_outdir = default.wf_outdir
    if wf_outdir is not None:
        wf_outdir_p = Path("/root/").resolve() # superhack
        wf_paths[wf_outdir] = wf_outdir_p


    channel_vals = [json.loads(default.channel_1489),json.loads(default.channel_1490),json.loads(default.channel_1491),json.loads(default.channel_1492)]

    download_files(channel_vals, LatchDir('latch://1721.account/Nextflow Outputs/'))

    try:
        subprocess.run(
            ['/root/nextflow','run','main.nf','-profile','mamba','--input',str(wf_paths[wf_input]),'--outdir',str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_INCLUDE_META": '{"path": "./modules/nf-core/multiqc/main.nf", "alias": "MULTIQC", "name": "MULTIQC"}',
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"data\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"plots\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)

        import time
        time.sleep(10000)

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = file.read_text()

    print(out_channels)

    upload_files({k: json.loads(v) for k, v in out_channels.items()}, LatchDir('latch://1721.account/Nextflow Outputs/'))

    return Dataclass_1493_post(
        report=out_channels.get(f"report", ""),
        data=out_channels.get(f"data", ""),
        plots=out_channels.get(f"plots", ""),
        versions=out_channels.get(f"versions", "")
    )


class RestoList_1494(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_1494(
    wf_input: LatchFile,
    wf_outdir: LatchOutputDir,
    report: typing.Union[str, None]
) -> RestoList_1494:
    cond = ((report is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths[wf_input] = Path("/root") / wf_input_p.name

        if wf_outdir is not None:
            wf_outdir_p = Path("/root/").resolve() # superhack
            wf_paths[wf_outdir] = wf_outdir_p

        channel_vals = [json.loads(report)]



        subprocess.run(
            ['/root/nextflow', 'run', 'main.nf', '--input', str(wf_paths[wf_input]), '--outdir', str(wf_paths[wf_outdir])],
            env={
                **os.environ,
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
            },
            check=True,
        )

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = file.read_text()



    else:
        print("TASK SKIPPED")
        out_channels = {'res': None}

    return RestoList_1494(
        res=out_channels.get("res", "")
    )
